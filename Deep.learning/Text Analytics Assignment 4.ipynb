{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Text Analytics Assignment 4.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"QfYV9X_aKyHk","colab_type":"code","colab":{}},"source":["from sklearn.datasets import load_files  \n","import numpy as np\n","import pandas as pd\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from nltk.corpus import stopwords\n","import nltk\n","from nltk import WhitespaceTokenizer\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report \n","from sklearn import metrics \n","from sklearn.metrics import f1_score\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.metrics import auc\n","from sklearn.utils import resample\n","from keras.models import Sequential"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"arAwG1oCDrYE","colab_type":"code","outputId":"05f9ccf1-cfe9-40cc-909a-48d3ea4f66e4","executionInfo":{"status":"ok","timestamp":1583867237920,"user_tz":-120,"elapsed":6442,"user":{"displayName":"Panagiotis Kolozis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjr5mKsFQESGYRkXpGpagCBYUv0mGlapc3Ok6ff0Q=s64","userId":"00962902516379623090"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["# download the dataset\n","!wget http://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz\n","!tar xzf review_polarity.tar.gz"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2020-03-10 19:07:13--  http://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz\n","Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.20\n","Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.20|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3127238 (3.0M) [application/x-gzip]\n","Saving to: ‘review_polarity.tar.gz’\n","\n","review_polarity.tar 100%[===================>]   2.98M  1.43MB/s    in 2.1s    \n","\n","2020-03-10 19:07:16 (1.43 MB/s) - ‘review_polarity.tar.gz’ saved [3127238/3127238]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ESk3N66AKwpu","colab_type":"code","colab":{}},"source":["# load the dataset\n","movies = load_files(\"txt_sentoken\", encoding=\"utf-8\")  \n","x, y = movies.data, movies.target"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G9bqc9ZkK34U","colab_type":"code","outputId":"624a516a-6788-4df6-af2b-1977d56160c0","executionInfo":{"status":"ok","timestamp":1583867428757,"user_tz":-120,"elapsed":187760,"user":{"displayName":"Panagiotis Kolozis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjr5mKsFQESGYRkXpGpagCBYUv0mGlapc3Ok6ff0Q=s64","userId":"00962902516379623090"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["nltk.download('stopwords')\n","# tokenize the sentences\n","whitespace_wt = WhitespaceTokenizer()\n","sentences_tokenized = []\n","for sent in x:\n","    sent_tok = whitespace_wt.tokenize(sent)\n","    sentences_tokenized.append(sent_tok)\n","# remove the stop words from the corpus\n","filtered = []\n","for words in sentences_tokenized:\n","      filtered.append([j for j in words if j not in stopwords.words('english')])\n","# stitch the tokens back to sentences\n","e = [\" \".join(i) for i in filtered ]\n","# remove the punctuation , lower case all the words and tokenize with keras\n","tokenizer = Tokenizer(num_words=None,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',lower=True,oov_token='__UNK__')\n","tokenizer.fit_on_texts(e)\n","x_ = tokenizer.texts_to_sequences(e)\n","vocab = len(tokenizer.word_index) + 1\n","max_length = max([len(x_[i]) for i in range(len(x_))])\n","# padd with zeros to create a uniform matrix\n","x_tokeniz = pad_sequences(x_, maxlen=max_length,padding='post')\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m2-UwESbtB4f","colab_type":"code","colab":{}},"source":["# split the dataset into train and test set in ratio 9/1\n","x_train, x_test, y_train, y_test = train_test_split(x_tokeniz, y, test_size=0.1, random_state=8888)\n","# split the dataset into train and developement set\n","x_train, x_dev, y_train, y_dev = train_test_split(x_train, y_train, test_size=0.1, random_state=8888)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vvfGr82olqCC","colab_type":"code","outputId":"fa380f17-7208-4ea5-da54-c1a758c977e4","executionInfo":{"status":"ok","timestamp":1583494359794,"user_tz":-120,"elapsed":195192,"user":{"displayName":"Panagiotis Kolozis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjr5mKsFQESGYRkXpGpagCBYUv0mGlapc3Ok6ff0Q=s64","userId":"00962902516379623090"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz\n","!gzip -d cc.en.300.vec.gz"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2020-03-06 11:29:26--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz\n","Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.22.166, 104.20.6.166, 2606:4700:10::6814:6a6, ...\n","Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.22.166|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1325960915 (1.2G) [binary/octet-stream]\n","Saving to: ‘cc.en.300.vec.gz’\n","\n","cc.en.300.vec.gz    100%[===================>]   1.23G  11.7MB/s    in 1m 49s  \n","\n","2020-03-06 11:31:16 (11.6 MB/s) - ‘cc.en.300.vec.gz’ saved [1325960915/1325960915]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kHyXSkSmeQJY","colab_type":"code","outputId":"5c79c04f-f29b-45e1-cb32-1b76cadf9359","executionInfo":{"status":"ok","timestamp":1583494871071,"user_tz":-120,"elapsed":406120,"user":{"displayName":"Panagiotis Kolozis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjr5mKsFQESGYRkXpGpagCBYUv0mGlapc3Ok6ff0Q=s64","userId":"00962902516379623090"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["word_index = tokenizer.word_index\n","# Get the words of our vocabulary\n","vocab_words = list(word_index.keys())\n","\n","embeddings_index = {}\n","\n","with open(\"cc.en.300.vec\", \"r\", encoding=\"utf-8\", newline=\"\\n\",errors=\"ignore\") as f:\n","  for l in tqdm(f):\n","    values = l.split()\n","    if len(values) == 2:\n","      embedding_dim = int(values[1])\n","    else:\n","      word = values[0]\n","      embeddings_index[word] = np.array(values[1:]).astype(np.float)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2000001it [06:45, 4934.84it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"_XVrTmkOoE0E","colab_type":"code","outputId":"1c7e03a8-8bb0-45f7-f1b6-37d099a2f2ad","executionInfo":{"status":"ok","timestamp":1583494875820,"user_tz":-120,"elapsed":1063,"user":{"displayName":"Panagiotis Kolozis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjr5mKsFQESGYRkXpGpagCBYUv0mGlapc3Ok6ff0Q=s64","userId":"00962902516379623090"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["embedding_matrix = np.zeros((vocab, embedding_dim))\n","for word in tqdm(vocab_words):\n","  try:\n","    index = word_index[word]\n","    embedding_matrix[index] = embeddings_index[word]\n","  except:\n","    pass"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 43266/43266 [00:00<00:00, 360251.16it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"fATdVRXRoXUu","colab_type":"code","colab":{}},"source":["np.save(\"embedding_matrix.npy\", embedding_matrix, allow_pickle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cIO72Gq0XQSC","colab_type":"code","colab":{}},"source":["# load the pretrained word embeddings\n","embedding_matrix = np.load(\"/content/drive/My Drive/Colab Notebooks/embedding_matrix.npy\")\n","embedding_dim = len(embedding_matrix[1])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9zaCYyzXsG5k","colab_type":"code","colab":{}},"source":["def recall(y_true, y_pred):\n","    \n","    \"\"\"\n","    Recall metric.\n","    Only computes a batch-wise average of recall.\n","    Computes the recall, a metric for multi-label classification of\n","    how many relevant items are selected.\n","    \"\"\"\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","    recall = true_positives / (possible_positives + K.epsilon())\n","    return recall\n","\n","\n","def precision(y_true, y_pred):\n","    \n","    \"\"\"\n","    Precision metric.\n","    Only computes a batch-wise average of precision.\n","    Computes the precision, a metric for multi-label classification of\n","    how many selected items are relevant.\n","    Source\n","    ------\n","    https://github.com/fchollet/keras/issues/5400#issuecomment-314747992\n","    \"\"\"\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","    precision = true_positives / (predicted_positives + K.epsilon())\n","    return precision\n","\n","\n","def f1(y_true, y_pred):\n","    \n","    \"\"\"Calculate the F1 score.\"\"\"\n","    p = precision(y_true, y_pred)\n","    r = recall(y_true, y_pred)\n","    return 2 * ((p * r) / (p + r))\n","\n","\n","def accuracy(y_true, y_pred):\n","    return K.mean(K.equal(y_true, K.round(y_pred)), axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"I1cQ5d2zurnm","colab_type":"code","colab":{}},"source":["from keras import backend as K\n","from keras import initializers, regularizers, constraints\n","from keras.layers.core import Layer\n","\n","def dot_product(x, kernel):\n","    \"\"\"\n","    Wrapper for dot product operation, in order to be compatible with both\n","    Theano and Tensorflow\n","    Args:\n","        x (): input\n","        kernel (): weights\n","    Returns:\n","    \"\"\"\n","    if K.backend() == 'tensorflow':\n","        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n","    else:\n","        return K.dot(x, kernel)\n","\n","\n","class LinearAttention(Layer):\n","    def __init__(self,\n","                 kernel_regularizer=None, bias_regularizer=None,\n","                 W_constraint=None, b_constraint=None,\n","                 bias=True,\n","                 return_attention=False,\n","                 **kwargs):\n","        \n","        self.supports_masking = True\n","        self.init = initializers.get('glorot_uniform')\n","\n","        self.W_regularizer = regularizers.get(kernel_regularizer)\n","        self.b_regularizer = regularizers.get(bias_regularizer)\n","\n","        self.W_constraint = constraints.get(W_constraint)\n","        self.b_constraint = constraints.get(b_constraint)\n","\n","        self.bias = bias\n","        self.return_attention = return_attention\n","        super(LinearAttention, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        assert len(input_shape) == 3\n","\n","        self.W = self.add_weight((input_shape[-1],),\n","                                 initializer=self.init,\n","                                 name='{}_W'.format(self.name),\n","                                 regularizer=self.W_regularizer,\n","                                 constraint=self.W_constraint)\n","        if self.bias:\n","            self.b = self.add_weight((1,),\n","                                     initializer='zero',\n","                                     name='{}_b'.format(self.name),\n","                                     regularizer=self.b_regularizer,\n","                                     constraint=self.b_constraint)\n","        else:\n","            self.b = None\n","\n","        self.built = True\n","\n","    def compute_mask(self, inputs, mask=None):\n","        # do not pass the mask to the next layers\n","        if self.return_attention:\n","            return [None, None]\n","        return None\n","\n","    def call(self, x, mask=None):\n","        \n","        # eij = Wx + b\n","        eij = dot_product(x, self.W)\n","\n","        if self.bias:\n","            eij += self.b\n","\n","        # Apply mask\n","        if mask is not None:\n","            eij *= K.cast(mask, K.floatx())\n","\n","        # a = softmax(eij)\n","        a = K.expand_dims(K.softmax(eij, axis=-1))\n","        weighted_input = x * a\n","        result = K.sum(weighted_input, axis=1)\n","\n","        if self.return_attention:\n","            return [result, a]\n","        return result\n","\n","    def compute_output_shape(self, input_shape):\n","        if self.return_attention:\n","            return [(input_shape[0], input_shape[-1]),\n","                    (input_shape[0], input_shape[1])]\n","        else:\n","            return input_shape[0], input_shape[-1]\n","\n","\n","class DeepAttention(Layer):\n","    def __init__(self,\n","                 kernel_regularizer=None, u_regularizer=None, bias_regularizer=None,\n","                 W_constraint=None, u_constraint=None, b_constraint=None,\n","                 bias=True,\n","                 return_attention=False,\n","                 **kwargs):\n","\n","        self.supports_masking = True\n","        self.init = initializers.get('glorot_uniform')\n","\n","        self.W_regularizer = regularizers.get(kernel_regularizer)\n","        self.u_regularizer = regularizers.get(u_regularizer)\n","        self.b1_regularizer = regularizers.get(bias_regularizer)\n","        self.b2_regularizer = regularizers.get(bias_regularizer)\n","\n","        self.W_constraint = constraints.get(W_constraint)\n","        self.u_constraint = constraints.get(u_constraint)\n","        self.b1_constraint = constraints.get(b_constraint)\n","        self.b2_constraint = constraints.get(b_constraint)\n","\n","        self.bias = bias\n","        self.return_attention = return_attention\n","        super(DeepAttention, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        assert len(input_shape) == 3\n","\n","        self.W = self.add_weight((input_shape[-1], input_shape[-1],),\n","                                 initializer=self.init,\n","                                 name='{}_W'.format(self.name),\n","                                 regularizer=self.W_regularizer,\n","                                 constraint=self.W_constraint)\n","        if self.bias:\n","            self.b1 = self.add_weight((input_shape[-1],),\n","                                     initializer='zero',\n","                                     name='{}_b1'.format(self.name),\n","                                     regularizer=self.b1_regularizer,\n","                                     constraint=self.b1_constraint)\n","            self.b2 = self.add_weight((1,),\n","                                     initializer='zero',\n","                                     name='{}_b2'.format(self.name),\n","                                     regularizer=self.b2_regularizer,\n","                                     constraint=self.b2_constraint)\n","        else:\n","            self.b1 = None\n","            self.b2 = None\n","\n","        self.u = self.add_weight((input_shape[-1],),\n","                                 initializer=self.init,\n","                                 name='{}_u'.format(self.name),\n","                                 regularizer=self.u_regularizer,\n","                                 constraint=self.u_constraint)\n","\n","        self.built = True\n","\n","\n","    def compute_mask(self, inputs, mask=None):\n","        # do not pass the mask to the next layers\n","        if self.return_attention:\n","            return [None, None]\n","        return None\n","\n","    def call(self, x, mask=None):\n","        # uit = tanh(Wx + b)\n","        uit = dot_product(x, self.W)\n","\n","        if self.bias:\n","            uit += self.b1\n","\n","        uit = K.tanh(uit)\n","\n","        # ait = softmax(Ueij)\n","        eij = dot_product(uit, self.u)\n","        if self.bias:\n","            eij += self.b2\n","\n","        # Apply mask\n","        if mask is not None:\n","            eij *= K.cast(mask, K.floatx())\n","\n","        a = K.expand_dims(K.softmax(eij, axis=-1))\n","        \n","        weighted_input = x * a\n","        result = K.sum(weighted_input, axis=1)\n","\n","        if self.return_attention:\n","            return [result, a]\n","        return result\n","\n","    def compute_output_shape(self, input_shape):\n","        if self.return_attention:\n","            return [(input_shape[0], input_shape[-1]),\n","                    (input_shape[0], input_shape[1])]\n","        else:\n","            return input_shape[0], input_shape[-1]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jy1fa5Eix0TT","colab_type":"code","outputId":"0ce80d54-aff5-4e2b-c33b-bd20d8d06b80","executionInfo":{"status":"ok","timestamp":1583879982972,"user_tz":-120,"elapsed":12126132,"user":{"displayName":"Panagiotis Kolozis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjr5mKsFQESGYRkXpGpagCBYUv0mGlapc3Ok6ff0Q=s64","userId":"00962902516379623090"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import warnings\n","import sklearn.exceptions\n","warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","from keras.callbacks import ModelCheckpoint\n","from keras.layers.embeddings import Embedding\n","from keras.models import Model\n","from keras.layers import Dense, Dropout, Bidirectional, Input\n","from keras.layers.recurrent import LSTM\n","from keras.optimizers import Adam\n","from keras import backend as K\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","LSTM_SIZE = 100\n","DENSE = 150\n","N_CLASSES = 1\n","\n","inputs = Input((max_length,))\n","embeddings = Embedding(vocab,embedding_dim, weights=[embedding_matrix], \n","                    input_length=max_length, mask_zero=True, trainable=False)(inputs)\n","drop_emb = Dropout(0.5)(embeddings)\n","bilstm = Bidirectional(LSTM(units=LSTM_SIZE, return_sequences=True,recurrent_dropout = 0.2))(drop_emb)\n","bilstm = Bidirectional(LSTM(units=LSTM_SIZE, return_sequences=True,recurrent_dropout = 0.3))(bilstm)\n","# x, attn = LinearAttention(return_attention=True)(bilstm)\n","x, attn = DeepAttention(return_attention=True)(bilstm)\n","out = Dense(units=DENSE, activation=\"relu\")(x) \n","out = Dense(units=N_CLASSES, activation=\"sigmoid\")(out)\n","model = Model(inputs, out)\n","\n","print(model.summary())\n","model.compile(loss='binary_crossentropy',\n","                  optimizer=Adam(lr=0.0001),\n","                  metrics=[precision, recall, f1, accuracy])\n","\n","checkpoint = ModelCheckpoint('keras_BiLSTM+attn_model', monitor='val_loss', verbose=2, save_best_only=True, mode='min')\n","early_stop = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=4, restore_best_weights=True)\n","\n","history = model.fit(x_train, y_train,\n","              batch_size=200,\n","              epochs=100,\n","              verbose = 2,\n","              callbacks=[checkpoint,early_stop],\n","              validation_data=(x_dev,y_dev),\n","              shuffle=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"model_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_3 (InputLayer)         (None, 1410)              0         \n","_________________________________________________________________\n","embedding_3 (Embedding)      (None, 1410, 300)         12980100  \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 1410, 300)         0         \n","_________________________________________________________________\n","bidirectional_3 (Bidirection (None, 1410, 200)         320800    \n","_________________________________________________________________\n","bidirectional_4 (Bidirection (None, 1410, 200)         240800    \n","_________________________________________________________________\n","deep_attention_2 (DeepAttent [(None, 200), (None, 1410 40401     \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 150)               30150     \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 151       \n","=================================================================\n","Total params: 13,612,402\n","Trainable params: 632,302\n","Non-trainable params: 12,980,100\n","_________________________________________________________________\n","None\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","Train on 1620 samples, validate on 180 samples\n","Epoch 1/100\n"," - 157s - loss: 0.6933 - precision: 0.5006 - recall: 0.8558 - f1: 0.6296 - accuracy: 0.4988 - val_loss: 0.6931 - val_precision: 0.4834 - val_recall: 0.8391 - val_f1: 0.6134 - val_accuracy: 0.4889\n","\n","Epoch 00001: val_loss improved from inf to 0.69308, saving model to keras_BiLSTM+attn_model\n","Epoch 2/100\n"," - 152s - loss: 0.6928 - precision: 0.5221 - recall: 0.8154 - f1: 0.6350 - accuracy: 0.5309 - val_loss: 0.6926 - val_precision: 0.5417 - val_recall: 0.7471 - val_f1: 0.6280 - val_accuracy: 0.5722\n","\n","Epoch 00002: val_loss improved from 0.69308 to 0.69264, saving model to keras_BiLSTM+attn_model\n","Epoch 3/100\n"," - 153s - loss: 0.6922 - precision: 0.5345 - recall: 0.8238 - f1: 0.6469 - accuracy: 0.5519 - val_loss: 0.6922 - val_precision: 0.5105 - val_recall: 0.8391 - val_f1: 0.6348 - val_accuracy: 0.5333\n","\n","Epoch 00003: val_loss improved from 0.69264 to 0.69219, saving model to keras_BiLSTM+attn_model\n","Epoch 4/100\n"," - 152s - loss: 0.6915 - precision: 0.5363 - recall: 0.8892 - f1: 0.6681 - accuracy: 0.5586 - val_loss: 0.6917 - val_precision: 0.5192 - val_recall: 0.9310 - val_f1: 0.6667 - val_accuracy: 0.5500\n","\n","Epoch 00004: val_loss improved from 0.69219 to 0.69166, saving model to keras_BiLSTM+attn_model\n","Epoch 5/100\n"," - 153s - loss: 0.6908 - precision: 0.5277 - recall: 0.9350 - f1: 0.6735 - accuracy: 0.5488 - val_loss: 0.6910 - val_precision: 0.5030 - val_recall: 0.9655 - val_f1: 0.6614 - val_accuracy: 0.5222\n","\n","Epoch 00005: val_loss improved from 0.69166 to 0.69101, saving model to keras_BiLSTM+attn_model\n","Epoch 6/100\n"," - 153s - loss: 0.6893 - precision: 0.5187 - recall: 0.9751 - f1: 0.6762 - accuracy: 0.5346 - val_loss: 0.6905 - val_precision: 0.4914 - val_recall: 0.9885 - val_f1: 0.6565 - val_accuracy: 0.5000\n","\n","Epoch 00006: val_loss improved from 0.69101 to 0.69051, saving model to keras_BiLSTM+attn_model\n","Epoch 7/100\n"," - 153s - loss: 0.6881 - precision: 0.5111 - recall: 0.9865 - f1: 0.6727 - accuracy: 0.5204 - val_loss: 0.6891 - val_precision: 0.4943 - val_recall: 0.9885 - val_f1: 0.6590 - val_accuracy: 0.5056\n","\n","Epoch 00007: val_loss improved from 0.69051 to 0.68911, saving model to keras_BiLSTM+attn_model\n","Epoch 8/100\n"," - 153s - loss: 0.6855 - precision: 0.5119 - recall: 0.9774 - f1: 0.6708 - accuracy: 0.5216 - val_loss: 0.6858 - val_precision: 0.5153 - val_recall: 0.9655 - val_f1: 0.6720 - val_accuracy: 0.5444\n","\n","Epoch 00008: val_loss improved from 0.68911 to 0.68582, saving model to keras_BiLSTM+attn_model\n","Epoch 9/100\n"," - 153s - loss: 0.6807 - precision: 0.5772 - recall: 0.8996 - f1: 0.7021 - accuracy: 0.6173 - val_loss: 0.6801 - val_precision: 0.6055 - val_recall: 0.7586 - val_f1: 0.6735 - val_accuracy: 0.6444\n","\n","Epoch 00009: val_loss improved from 0.68582 to 0.68008, saving model to keras_BiLSTM+attn_model\n","Epoch 10/100\n"," - 153s - loss: 0.6733 - precision: 0.6648 - recall: 0.7496 - f1: 0.7029 - accuracy: 0.6852 - val_loss: 0.6693 - val_precision: 0.5748 - val_recall: 0.8391 - val_f1: 0.6822 - val_accuracy: 0.6222\n","\n","Epoch 00010: val_loss improved from 0.68008 to 0.66929, saving model to keras_BiLSTM+attn_model\n","Epoch 11/100\n"," - 153s - loss: 0.6603 - precision: 0.5601 - recall: 0.9485 - f1: 0.7028 - accuracy: 0.5981 - val_loss: 0.6483 - val_precision: 0.6569 - val_recall: 0.7701 - val_f1: 0.7090 - val_accuracy: 0.6944\n","\n","Epoch 00011: val_loss improved from 0.66929 to 0.64833, saving model to keras_BiLSTM+attn_model\n","Epoch 12/100\n"," - 152s - loss: 0.6318 - precision: 0.6661 - recall: 0.8023 - f1: 0.7255 - accuracy: 0.6963 - val_loss: 0.6097 - val_precision: 0.7662 - val_recall: 0.6782 - val_f1: 0.7195 - val_accuracy: 0.7444\n","\n","Epoch 00012: val_loss improved from 0.64833 to 0.60972, saving model to keras_BiLSTM+attn_model\n","Epoch 13/100\n"," - 153s - loss: 0.6061 - precision: 0.7068 - recall: 0.6859 - f1: 0.6905 - accuracy: 0.6944 - val_loss: 0.5733 - val_precision: 0.7612 - val_recall: 0.5862 - val_f1: 0.6623 - val_accuracy: 0.7111\n","\n","Epoch 00013: val_loss improved from 0.60972 to 0.57332, saving model to keras_BiLSTM+attn_model\n","Epoch 14/100\n"," - 152s - loss: 0.5789 - precision: 0.7745 - recall: 0.6165 - f1: 0.6803 - accuracy: 0.7148 - val_loss: 0.5607 - val_precision: 0.7174 - val_recall: 0.7586 - val_f1: 0.7374 - val_accuracy: 0.7389\n","\n","Epoch 00014: val_loss improved from 0.57332 to 0.56065, saving model to keras_BiLSTM+attn_model\n","Epoch 15/100\n"," - 152s - loss: 0.5675 - precision: 0.7699 - recall: 0.6933 - f1: 0.7194 - accuracy: 0.7333 - val_loss: 0.5591 - val_precision: 0.7576 - val_recall: 0.5747 - val_f1: 0.6536 - val_accuracy: 0.7056\n","\n","Epoch 00015: val_loss improved from 0.56065 to 0.55913, saving model to keras_BiLSTM+attn_model\n","Epoch 16/100\n"," - 152s - loss: 0.5587 - precision: 0.7214 - recall: 0.7432 - f1: 0.7308 - accuracy: 0.7265 - val_loss: 0.5449 - val_precision: 0.7500 - val_recall: 0.6207 - val_f1: 0.6792 - val_accuracy: 0.7167\n","\n","Epoch 00016: val_loss improved from 0.55913 to 0.54491, saving model to keras_BiLSTM+attn_model\n","Epoch 17/100\n"," - 153s - loss: 0.5421 - precision: 0.7666 - recall: 0.6901 - f1: 0.7250 - accuracy: 0.7389 - val_loss: 0.5297 - val_precision: 0.7532 - val_recall: 0.6667 - val_f1: 0.7073 - val_accuracy: 0.7333\n","\n","Epoch 00017: val_loss improved from 0.54491 to 0.52973, saving model to keras_BiLSTM+attn_model\n","Epoch 18/100\n"," - 152s - loss: 0.5324 - precision: 0.7450 - recall: 0.7402 - f1: 0.7416 - accuracy: 0.7426 - val_loss: 0.5264 - val_precision: 0.7639 - val_recall: 0.6322 - val_f1: 0.6918 - val_accuracy: 0.7278\n","\n","Epoch 00018: val_loss improved from 0.52973 to 0.52641, saving model to keras_BiLSTM+attn_model\n","Epoch 19/100\n"," - 153s - loss: 0.5308 - precision: 0.7657 - recall: 0.7171 - f1: 0.7401 - accuracy: 0.7481 - val_loss: 0.5178 - val_precision: 0.7838 - val_recall: 0.6667 - val_f1: 0.7205 - val_accuracy: 0.7500\n","\n","Epoch 00019: val_loss improved from 0.52641 to 0.51784, saving model to keras_BiLSTM+attn_model\n","Epoch 20/100\n"," - 152s - loss: 0.5250 - precision: 0.7731 - recall: 0.7158 - f1: 0.7422 - accuracy: 0.7537 - val_loss: 0.5121 - val_precision: 0.7595 - val_recall: 0.6897 - val_f1: 0.7229 - val_accuracy: 0.7444\n","\n","Epoch 00020: val_loss improved from 0.51784 to 0.51215, saving model to keras_BiLSTM+attn_model\n","Epoch 21/100\n"," - 153s - loss: 0.5120 - precision: 0.7523 - recall: 0.7635 - f1: 0.7561 - accuracy: 0.7549 - val_loss: 0.5141 - val_precision: 0.7794 - val_recall: 0.6092 - val_f1: 0.6839 - val_accuracy: 0.7278\n","\n","Epoch 00021: val_loss did not improve from 0.51215\n","Epoch 22/100\n"," - 152s - loss: 0.5171 - precision: 0.8099 - recall: 0.6606 - f1: 0.7238 - accuracy: 0.7506 - val_loss: 0.5072 - val_precision: 0.7172 - val_recall: 0.8161 - val_f1: 0.7634 - val_accuracy: 0.7556\n","\n","Epoch 00022: val_loss improved from 0.51215 to 0.50720, saving model to keras_BiLSTM+attn_model\n","Epoch 23/100\n"," - 153s - loss: 0.5269 - precision: 0.7524 - recall: 0.7876 - f1: 0.7644 - accuracy: 0.7568 - val_loss: 0.5211 - val_precision: 0.8060 - val_recall: 0.6207 - val_f1: 0.7013 - val_accuracy: 0.7444\n","\n","Epoch 00023: val_loss did not improve from 0.50720\n","Epoch 24/100\n"," - 154s - loss: 0.5061 - precision: 0.7942 - recall: 0.7183 - f1: 0.7508 - accuracy: 0.7623 - val_loss: 0.5014 - val_precision: 0.7447 - val_recall: 0.8046 - val_f1: 0.7735 - val_accuracy: 0.7722\n","\n","Epoch 00024: val_loss improved from 0.50720 to 0.50136, saving model to keras_BiLSTM+attn_model\n","Epoch 25/100\n"," - 155s - loss: 0.5126 - precision: 0.7327 - recall: 0.8197 - f1: 0.7684 - accuracy: 0.7537 - val_loss: 0.5009 - val_precision: 0.7778 - val_recall: 0.6437 - val_f1: 0.7044 - val_accuracy: 0.7389\n","\n","Epoch 00025: val_loss improved from 0.50136 to 0.50093, saving model to keras_BiLSTM+attn_model\n","Epoch 26/100\n"," - 154s - loss: 0.4979 - precision: 0.7972 - recall: 0.7504 - f1: 0.7688 - accuracy: 0.7753 - val_loss: 0.4792 - val_precision: 0.7654 - val_recall: 0.7126 - val_f1: 0.7381 - val_accuracy: 0.7556\n","\n","Epoch 00026: val_loss improved from 0.50093 to 0.47920, saving model to keras_BiLSTM+attn_model\n","Epoch 27/100\n"," - 156s - loss: 0.4843 - precision: 0.7707 - recall: 0.7841 - f1: 0.7764 - accuracy: 0.7735 - val_loss: 0.4834 - val_precision: 0.7763 - val_recall: 0.6782 - val_f1: 0.7239 - val_accuracy: 0.7500\n","\n","Epoch 00027: val_loss did not improve from 0.47920\n","Epoch 28/100\n"," - 155s - loss: 0.4859 - precision: 0.7840 - recall: 0.7764 - f1: 0.7797 - accuracy: 0.7827 - val_loss: 0.4717 - val_precision: 0.7791 - val_recall: 0.7701 - val_f1: 0.7746 - val_accuracy: 0.7833\n","\n","Epoch 00028: val_loss improved from 0.47920 to 0.47169, saving model to keras_BiLSTM+attn_model\n","Epoch 29/100\n"," - 157s - loss: 0.4698 - precision: 0.7589 - recall: 0.8294 - f1: 0.7918 - accuracy: 0.7840 - val_loss: 0.4789 - val_precision: 0.7703 - val_recall: 0.6552 - val_f1: 0.7081 - val_accuracy: 0.7389\n","\n","Epoch 00029: val_loss did not improve from 0.47169\n","Epoch 30/100\n"," - 156s - loss: 0.4766 - precision: 0.8049 - recall: 0.7573 - f1: 0.7765 - accuracy: 0.7833 - val_loss: 0.4659 - val_precision: 0.7901 - val_recall: 0.7356 - val_f1: 0.7619 - val_accuracy: 0.7778\n","\n","Epoch 00030: val_loss improved from 0.47169 to 0.46589, saving model to keras_BiLSTM+attn_model\n","Epoch 31/100\n"," - 155s - loss: 0.4830 - precision: 0.7793 - recall: 0.7629 - f1: 0.7705 - accuracy: 0.7735 - val_loss: 0.4706 - val_precision: 0.7778 - val_recall: 0.7241 - val_f1: 0.7500 - val_accuracy: 0.7667\n","\n","Epoch 00031: val_loss did not improve from 0.46589\n","Epoch 32/100\n"," - 154s - loss: 0.4659 - precision: 0.8034 - recall: 0.7836 - f1: 0.7930 - accuracy: 0.7957 - val_loss: 0.4666 - val_precision: 0.7882 - val_recall: 0.7701 - val_f1: 0.7791 - val_accuracy: 0.7889\n","\n","Epoch 00032: val_loss did not improve from 0.46589\n","Epoch 33/100\n"," - 156s - loss: 0.4472 - precision: 0.7906 - recall: 0.8145 - f1: 0.8005 - accuracy: 0.7975 - val_loss: 0.4680 - val_precision: 0.7945 - val_recall: 0.6667 - val_f1: 0.7250 - val_accuracy: 0.7556\n","\n","Epoch 00033: val_loss did not improve from 0.46589\n","Epoch 34/100\n"," - 156s - loss: 0.4577 - precision: 0.7826 - recall: 0.7889 - f1: 0.7842 - accuracy: 0.7833 - val_loss: 0.4647 - val_precision: 0.7945 - val_recall: 0.6667 - val_f1: 0.7250 - val_accuracy: 0.7556\n","\n","Epoch 00034: val_loss improved from 0.46589 to 0.46468, saving model to keras_BiLSTM+attn_model\n","Epoch 35/100\n"," - 155s - loss: 0.4465 - precision: 0.8195 - recall: 0.7878 - f1: 0.7965 - accuracy: 0.8012 - val_loss: 0.4523 - val_precision: 0.7841 - val_recall: 0.7931 - val_f1: 0.7886 - val_accuracy: 0.7944\n","\n","Epoch 00035: val_loss improved from 0.46468 to 0.45232, saving model to keras_BiLSTM+attn_model\n","Epoch 36/100\n"," - 154s - loss: 0.4413 - precision: 0.8195 - recall: 0.7730 - f1: 0.7939 - accuracy: 0.8000 - val_loss: 0.4481 - val_precision: 0.8272 - val_recall: 0.7701 - val_f1: 0.7976 - val_accuracy: 0.8111\n","\n","Epoch 00036: val_loss improved from 0.45232 to 0.44813, saving model to keras_BiLSTM+attn_model\n","Epoch 37/100\n"," - 155s - loss: 0.4438 - precision: 0.8093 - recall: 0.7831 - f1: 0.7947 - accuracy: 0.7988 - val_loss: 0.4456 - val_precision: 0.7955 - val_recall: 0.8046 - val_f1: 0.8000 - val_accuracy: 0.8056\n","\n","Epoch 00037: val_loss improved from 0.44813 to 0.44557, saving model to keras_BiLSTM+attn_model\n","Epoch 38/100\n"," - 155s - loss: 0.4440 - precision: 0.7719 - recall: 0.8378 - f1: 0.8006 - accuracy: 0.7938 - val_loss: 0.4612 - val_precision: 0.8143 - val_recall: 0.6552 - val_f1: 0.7261 - val_accuracy: 0.7611\n","\n","Epoch 00038: val_loss did not improve from 0.44557\n","Epoch 39/100\n"," - 155s - loss: 0.4393 - precision: 0.8134 - recall: 0.7808 - f1: 0.7934 - accuracy: 0.7981 - val_loss: 0.4463 - val_precision: 0.8049 - val_recall: 0.7586 - val_f1: 0.7811 - val_accuracy: 0.7944\n","\n","Epoch 00039: val_loss did not improve from 0.44557\n","Epoch 40/100\n"," - 157s - loss: 0.4266 - precision: 0.8308 - recall: 0.7739 - f1: 0.7977 - accuracy: 0.8049 - val_loss: 0.4459 - val_precision: 0.8133 - val_recall: 0.7011 - val_f1: 0.7531 - val_accuracy: 0.7778\n","\n","Epoch 00040: val_loss did not improve from 0.44557\n","Epoch 41/100\n"," - 156s - loss: 0.4392 - precision: 0.8620 - recall: 0.7270 - f1: 0.7872 - accuracy: 0.8043 - val_loss: 0.4455 - val_precision: 0.7742 - val_recall: 0.8276 - val_f1: 0.8000 - val_accuracy: 0.8000\n","\n","Epoch 00041: val_loss improved from 0.44557 to 0.44555, saving model to keras_BiLSTM+attn_model\n","Epoch 42/100\n"," - 157s - loss: 0.4353 - precision: 0.8021 - recall: 0.8392 - f1: 0.8164 - accuracy: 0.8105 - val_loss: 0.4465 - val_precision: 0.8333 - val_recall: 0.6897 - val_f1: 0.7547 - val_accuracy: 0.7833\n","\n","Epoch 00042: val_loss did not improve from 0.44555\n","Epoch 43/100\n"," - 155s - loss: 0.4251 - precision: 0.8218 - recall: 0.7890 - f1: 0.8036 - accuracy: 0.8080 - val_loss: 0.4351 - val_precision: 0.8148 - val_recall: 0.7586 - val_f1: 0.7857 - val_accuracy: 0.8000\n","\n","Epoch 00043: val_loss improved from 0.44555 to 0.43511, saving model to keras_BiLSTM+attn_model\n","Epoch 44/100\n"," - 152s - loss: 0.4214 - precision: 0.8455 - recall: 0.7623 - f1: 0.7987 - accuracy: 0.8093 - val_loss: 0.4365 - val_precision: 0.7766 - val_recall: 0.8391 - val_f1: 0.8066 - val_accuracy: 0.8056\n","\n","Epoch 00044: val_loss did not improve from 0.43511\n","Epoch 45/100\n"," - 146s - loss: 0.4050 - precision: 0.8233 - recall: 0.8282 - f1: 0.8240 - accuracy: 0.8241 - val_loss: 0.4356 - val_precision: 0.8356 - val_recall: 0.7011 - val_f1: 0.7625 - val_accuracy: 0.7889\n","\n","Epoch 00045: val_loss did not improve from 0.43511\n","Epoch 46/100\n"," - 152s - loss: 0.4036 - precision: 0.8210 - recall: 0.8255 - f1: 0.8218 - accuracy: 0.8216 - val_loss: 0.4207 - val_precision: 0.8235 - val_recall: 0.8046 - val_f1: 0.8140 - val_accuracy: 0.8222\n","\n","Epoch 00046: val_loss improved from 0.43511 to 0.42066, saving model to keras_BiLSTM+attn_model\n","Epoch 47/100\n"," - 152s - loss: 0.4045 - precision: 0.8345 - recall: 0.8059 - f1: 0.8184 - accuracy: 0.8222 - val_loss: 0.4229 - val_precision: 0.8514 - val_recall: 0.7241 - val_f1: 0.7826 - val_accuracy: 0.8056\n","\n","Epoch 00047: val_loss did not improve from 0.42066\n","Epoch 48/100\n"," - 154s - loss: 0.3874 - precision: 0.8432 - recall: 0.8317 - f1: 0.8357 - accuracy: 0.8377 - val_loss: 0.4233 - val_precision: 0.8514 - val_recall: 0.7241 - val_f1: 0.7826 - val_accuracy: 0.8056\n","\n","Epoch 00048: val_loss did not improve from 0.42066\n","Epoch 49/100\n"," - 146s - loss: 0.3891 - precision: 0.8432 - recall: 0.8161 - f1: 0.8281 - accuracy: 0.8327 - val_loss: 0.4180 - val_precision: 0.8140 - val_recall: 0.8046 - val_f1: 0.8092 - val_accuracy: 0.8167\n","\n","Epoch 00049: val_loss improved from 0.42066 to 0.41795, saving model to keras_BiLSTM+attn_model\n","Epoch 50/100\n"," - 146s - loss: 0.3907 - precision: 0.8308 - recall: 0.8308 - f1: 0.8298 - accuracy: 0.8302 - val_loss: 0.4223 - val_precision: 0.8533 - val_recall: 0.7356 - val_f1: 0.7901 - val_accuracy: 0.8111\n","\n","Epoch 00050: val_loss did not improve from 0.41795\n","Epoch 51/100\n"," - 149s - loss: 0.3861 - precision: 0.8503 - recall: 0.8165 - f1: 0.8320 - accuracy: 0.8352 - val_loss: 0.4154 - val_precision: 0.8256 - val_recall: 0.8161 - val_f1: 0.8208 - val_accuracy: 0.8278\n","\n","Epoch 00051: val_loss improved from 0.41795 to 0.41540, saving model to keras_BiLSTM+attn_model\n","Epoch 52/100\n"," - 152s - loss: 0.4111 - precision: 0.8267 - recall: 0.8079 - f1: 0.8158 - accuracy: 0.8179 - val_loss: 0.4153 - val_precision: 0.8353 - val_recall: 0.8161 - val_f1: 0.8256 - val_accuracy: 0.8333\n","\n","Epoch 00052: val_loss improved from 0.41540 to 0.41527, saving model to keras_BiLSTM+attn_model\n","Epoch 53/100\n"," - 152s - loss: 0.4029 - precision: 0.8200 - recall: 0.8367 - f1: 0.8274 - accuracy: 0.8265 - val_loss: 0.4270 - val_precision: 0.8451 - val_recall: 0.6897 - val_f1: 0.7595 - val_accuracy: 0.7889\n","\n","Epoch 00053: val_loss did not improve from 0.41527\n","Epoch 54/100\n"," - 147s - loss: 0.4012 - precision: 0.8504 - recall: 0.8073 - f1: 0.8230 - accuracy: 0.8278 - val_loss: 0.4137 - val_precision: 0.8111 - val_recall: 0.8391 - val_f1: 0.8249 - val_accuracy: 0.8278\n","\n","Epoch 00054: val_loss improved from 0.41527 to 0.41373, saving model to keras_BiLSTM+attn_model\n","Epoch 55/100\n"," - 146s - loss: 0.3920 - precision: 0.8587 - recall: 0.7969 - f1: 0.8247 - accuracy: 0.8327 - val_loss: 0.4073 - val_precision: 0.8276 - val_recall: 0.8276 - val_f1: 0.8276 - val_accuracy: 0.8333\n","\n","Epoch 00055: val_loss improved from 0.41373 to 0.40726, saving model to keras_BiLSTM+attn_model\n","Epoch 56/100\n"," - 155s - loss: 0.3853 - precision: 0.8422 - recall: 0.8398 - f1: 0.8391 - accuracy: 0.8395 - val_loss: 0.4041 - val_precision: 0.8313 - val_recall: 0.7931 - val_f1: 0.8118 - val_accuracy: 0.8222\n","\n","Epoch 00056: val_loss improved from 0.40726 to 0.40408, saving model to keras_BiLSTM+attn_model\n","Epoch 57/100\n"," - 150s - loss: 0.3803 - precision: 0.8275 - recall: 0.8684 - f1: 0.8462 - accuracy: 0.8432 - val_loss: 0.4170 - val_precision: 0.8649 - val_recall: 0.7356 - val_f1: 0.7950 - val_accuracy: 0.8167\n","\n","Epoch 00057: val_loss did not improve from 0.40408\n","Epoch 58/100\n"," - 154s - loss: 0.3838 - precision: 0.8505 - recall: 0.8348 - f1: 0.8391 - accuracy: 0.8414 - val_loss: 0.4076 - val_precision: 0.8684 - val_recall: 0.7586 - val_f1: 0.8098 - val_accuracy: 0.8278\n","\n","Epoch 00058: val_loss did not improve from 0.40408\n","Epoch 59/100\n"," - 154s - loss: 0.3893 - precision: 0.8470 - recall: 0.8184 - f1: 0.8308 - accuracy: 0.8340 - val_loss: 0.3998 - val_precision: 0.8333 - val_recall: 0.8046 - val_f1: 0.8187 - val_accuracy: 0.8278\n","\n","Epoch 00059: val_loss improved from 0.40408 to 0.39980, saving model to keras_BiLSTM+attn_model\n","Epoch 60/100\n"," - 155s - loss: 0.3724 - precision: 0.8501 - recall: 0.8233 - f1: 0.8353 - accuracy: 0.8389 - val_loss: 0.4053 - val_precision: 0.8571 - val_recall: 0.7586 - val_f1: 0.8049 - val_accuracy: 0.8222\n","\n","Epoch 00060: val_loss did not improve from 0.39980\n","Epoch 61/100\n"," - 155s - loss: 0.3734 - precision: 0.8591 - recall: 0.8180 - f1: 0.8358 - accuracy: 0.8395 - val_loss: 0.3982 - val_precision: 0.8395 - val_recall: 0.7816 - val_f1: 0.8095 - val_accuracy: 0.8222\n","\n","Epoch 00061: val_loss improved from 0.39980 to 0.39824, saving model to keras_BiLSTM+attn_model\n","Epoch 62/100\n"," - 154s - loss: 0.3716 - precision: 0.8796 - recall: 0.8128 - f1: 0.8396 - accuracy: 0.8457 - val_loss: 0.3973 - val_precision: 0.8372 - val_recall: 0.8276 - val_f1: 0.8324 - val_accuracy: 0.8389\n","\n","Epoch 00062: val_loss improved from 0.39824 to 0.39728, saving model to keras_BiLSTM+attn_model\n","Epoch 63/100\n"," - 155s - loss: 0.3652 - precision: 0.8823 - recall: 0.8030 - f1: 0.8391 - accuracy: 0.8463 - val_loss: 0.4070 - val_precision: 0.8111 - val_recall: 0.8391 - val_f1: 0.8249 - val_accuracy: 0.8278\n","\n","Epoch 00063: val_loss did not improve from 0.39728\n","Epoch 64/100\n"," - 155s - loss: 0.3705 - precision: 0.8286 - recall: 0.8632 - f1: 0.8440 - accuracy: 0.8407 - val_loss: 0.4076 - val_precision: 0.8590 - val_recall: 0.7701 - val_f1: 0.8121 - val_accuracy: 0.8278\n","\n","Epoch 00064: val_loss did not improve from 0.39728\n","Epoch 65/100\n"," - 157s - loss: 0.3617 - precision: 0.8657 - recall: 0.8179 - f1: 0.8400 - accuracy: 0.8457 - val_loss: 0.4014 - val_precision: 0.8090 - val_recall: 0.8276 - val_f1: 0.8182 - val_accuracy: 0.8222\n","\n","Epoch 00065: val_loss did not improve from 0.39728\n","Epoch 66/100\n"," - 155s - loss: 0.3522 - precision: 0.8654 - recall: 0.8386 - f1: 0.8493 - accuracy: 0.8519 - val_loss: 0.3966 - val_precision: 0.8090 - val_recall: 0.8276 - val_f1: 0.8182 - val_accuracy: 0.8222\n","\n","Epoch 00066: val_loss improved from 0.39728 to 0.39663, saving model to keras_BiLSTM+attn_model\n","Epoch 67/100\n"," - 154s - loss: 0.3625 - precision: 0.8443 - recall: 0.8535 - f1: 0.8481 - accuracy: 0.8481 - val_loss: 0.4076 - val_precision: 0.8701 - val_recall: 0.7701 - val_f1: 0.8171 - val_accuracy: 0.8333\n","\n","Epoch 00067: val_loss did not improve from 0.39663\n","Epoch 68/100\n"," - 154s - loss: 0.3833 - precision: 0.8725 - recall: 0.8087 - f1: 0.8351 - accuracy: 0.8420 - val_loss: 0.4065 - val_precision: 0.8043 - val_recall: 0.8506 - val_f1: 0.8268 - val_accuracy: 0.8278\n","\n","Epoch 00068: val_loss did not improve from 0.39663\n","Epoch 69/100\n"," - 154s - loss: 0.3816 - precision: 0.8378 - recall: 0.8080 - f1: 0.8214 - accuracy: 0.8253 - val_loss: 0.3925 - val_precision: 0.8046 - val_recall: 0.8046 - val_f1: 0.8046 - val_accuracy: 0.8111\n","\n","Epoch 00069: val_loss improved from 0.39663 to 0.39250, saving model to keras_BiLSTM+attn_model\n","Epoch 70/100\n"," - 154s - loss: 0.3763 - precision: 0.8140 - recall: 0.8776 - f1: 0.8436 - accuracy: 0.8389 - val_loss: 0.4029 - val_precision: 0.8933 - val_recall: 0.7701 - val_f1: 0.8272 - val_accuracy: 0.8444\n","\n","Epoch 00070: val_loss did not improve from 0.39250\n","Epoch 71/100\n"," - 154s - loss: 0.3692 - precision: 0.8691 - recall: 0.8099 - f1: 0.8337 - accuracy: 0.8407 - val_loss: 0.3917 - val_precision: 0.8111 - val_recall: 0.8391 - val_f1: 0.8249 - val_accuracy: 0.8278\n","\n","Epoch 00071: val_loss improved from 0.39250 to 0.39170, saving model to keras_BiLSTM+attn_model\n","Epoch 72/100\n"," - 153s - loss: 0.3489 - precision: 0.8877 - recall: 0.8215 - f1: 0.8514 - accuracy: 0.8574 - val_loss: 0.4034 - val_precision: 0.7835 - val_recall: 0.8736 - val_f1: 0.8261 - val_accuracy: 0.8222\n","\n","Epoch 00072: val_loss did not improve from 0.39170\n","Epoch 73/100\n"," - 153s - loss: 0.3633 - precision: 0.8408 - recall: 0.8737 - f1: 0.8541 - accuracy: 0.8512 - val_loss: 0.3913 - val_precision: 0.8625 - val_recall: 0.7931 - val_f1: 0.8263 - val_accuracy: 0.8389\n","\n","Epoch 00073: val_loss improved from 0.39170 to 0.39127, saving model to keras_BiLSTM+attn_model\n","Epoch 74/100\n"," - 151s - loss: 0.3572 - precision: 0.8602 - recall: 0.8408 - f1: 0.8493 - accuracy: 0.8512 - val_loss: 0.3872 - val_precision: 0.8182 - val_recall: 0.8276 - val_f1: 0.8229 - val_accuracy: 0.8278\n","\n","Epoch 00074: val_loss improved from 0.39127 to 0.38721, saving model to keras_BiLSTM+attn_model\n","Epoch 75/100\n"," - 154s - loss: 0.3561 - precision: 0.8734 - recall: 0.8189 - f1: 0.8441 - accuracy: 0.8488 - val_loss: 0.3860 - val_precision: 0.8090 - val_recall: 0.8276 - val_f1: 0.8182 - val_accuracy: 0.8222\n","\n","Epoch 00075: val_loss improved from 0.38721 to 0.38598, saving model to keras_BiLSTM+attn_model\n","Epoch 76/100\n"," - 153s - loss: 0.3552 - precision: 0.8627 - recall: 0.8456 - f1: 0.8529 - accuracy: 0.8556 - val_loss: 0.3940 - val_precision: 0.8022 - val_recall: 0.8391 - val_f1: 0.8202 - val_accuracy: 0.8222\n","\n","Epoch 00076: val_loss did not improve from 0.38598\n","Epoch 77/100\n"," - 152s - loss: 0.3420 - precision: 0.8588 - recall: 0.8412 - f1: 0.8488 - accuracy: 0.8506 - val_loss: 0.3919 - val_precision: 0.8022 - val_recall: 0.8391 - val_f1: 0.8202 - val_accuracy: 0.8222\n","\n","Epoch 00077: val_loss did not improve from 0.38598\n","Epoch 78/100\n"," - 153s - loss: 0.3520 - precision: 0.8390 - recall: 0.8472 - f1: 0.8411 - accuracy: 0.8401 - val_loss: 0.3927 - val_precision: 0.8642 - val_recall: 0.8046 - val_f1: 0.8333 - val_accuracy: 0.8444\n","\n","Epoch 00078: val_loss did not improve from 0.38598\n","Epoch 79/100\n"," - 154s - loss: 0.3593 - precision: 0.8586 - recall: 0.8538 - f1: 0.8543 - accuracy: 0.8549 - val_loss: 0.3909 - val_precision: 0.8022 - val_recall: 0.8391 - val_f1: 0.8202 - val_accuracy: 0.8222\n","\n","Epoch 00079: val_loss did not improve from 0.38598\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QzDAoRhv5I8p","colab_type":"code","outputId":"05faa238-8ecd-402f-c27f-b3668f76f1ae","executionInfo":{"status":"ok","timestamp":1583879984664,"user_tz":-120,"elapsed":1648,"user":{"displayName":"Panagiotis Kolozis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjr5mKsFQESGYRkXpGpagCBYUv0mGlapc3Ok6ff0Q=s64","userId":"00962902516379623090"}},"colab":{"base_uri":"https://localhost:8080/","height":573}},"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","\n","# summarize history for f1\n","plt.plot(history.history['f1'])\n","plt.plot(history.history['val_f1'])\n","plt.title('Model f1')\n","plt.ylabel('f1-score')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'dev'], loc='upper left')\n","plt.show()\n","# summarize history for loss\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'dev'], loc='upper right')\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlXKBMDOzUv8BgZaCqPPrLRkAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"4ChJaPRuJaQS","colab_type":"code","outputId":"33068df9-98cd-4153-878a-6d1a3faf0ea5","executionInfo":{"status":"ok","timestamp":1583880631884,"user_tz":-120,"elapsed":311557,"user":{"displayName":"Panagiotis Kolozis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjr5mKsFQESGYRkXpGpagCBYUv0mGlapc3Ok6ff0Q=s64","userId":"00962902516379623090"}},"colab":{"base_uri":"https://localhost:8080/","height":527}},"source":["# predict neural network in train set\n","predictions_nn_train = model.predict(np.array(x_train))\n","# threshold used t=0,5 (round())\n","print(\"Classification report for Neural network in train :\\n\",metrics.classification_report(y_train,np.round(predictions_nn_train)))\n","predictions_nn_dev = model.predict(np.array(x_dev))\n","# threshold used t=0,5 (round())\n","print(\"Classification report for Neural network in dev :\\n\",metrics.classification_report(y_dev,np.round(predictions_nn_dev)))\n","predictions_nn_test = model.predict(np.array(x_test))\n","# threshold used t=0,5 (round())\n","print(\"Classification report for Neural network in test :\\n\",metrics.classification_report(y_test,np.round(predictions_nn_test)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Classification report for Neural network in train :\n","               precision    recall  f1-score   support\n","\n","           0       0.88      0.92      0.90       809\n","           1       0.92      0.88      0.90       811\n","\n","    accuracy                           0.90      1620\n","   macro avg       0.90      0.90      0.90      1620\n","weighted avg       0.90      0.90      0.90      1620\n","\n","Classification report for Neural network in dev :\n","               precision    recall  f1-score   support\n","\n","           0       0.84      0.82      0.83        93\n","           1       0.81      0.83      0.82        87\n","\n","    accuracy                           0.82       180\n","   macro avg       0.82      0.82      0.82       180\n","weighted avg       0.82      0.82      0.82       180\n","\n","Classification report for Neural network in test :\n","               precision    recall  f1-score   support\n","\n","           0       0.83      0.85      0.84        98\n","           1       0.85      0.83      0.84       102\n","\n","    accuracy                           0.84       200\n","   macro avg       0.84      0.84      0.84       200\n","weighted avg       0.84      0.84      0.84       200\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"upM28p5SAMNB","colab_type":"code","outputId":"938f4ed5-bf67-4fe8-d083-4c3eccff2764","executionInfo":{"status":"ok","timestamp":1583880681237,"user_tz":-120,"elapsed":628,"user":{"displayName":"Panagiotis Kolozis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjr5mKsFQESGYRkXpGpagCBYUv0mGlapc3Ok6ff0Q=s64","userId":"00962902516379623090"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["print('F1 score with macro averaging in train set',f1_score(y_train,np.round(predictions_nn_train),average='macro'))\n","print('F1 score with macro averaging in dev set',f1_score(y_dev,np.round(predictions_nn_dev),average='macro'))\n","print('F1 score with macro averaging in test set',f1_score(y_test,np.round(predictions_nn_test),average='macro'))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["F1 score with macro averagin in train set 0.8999656946826757\n","F1 score with macro averagin in dev set 0.8221343873517787\n","F1 score with macro averagin in test set 0.8399839983998401\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LTYt3QVQBG99","colab_type":"code","outputId":"da727b7c-0009-447e-c166-8076cbb7e8cc","executionInfo":{"status":"ok","timestamp":1583880789250,"user_tz":-120,"elapsed":662,"user":{"displayName":"Panagiotis Kolozis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjr5mKsFQESGYRkXpGpagCBYUv0mGlapc3Ok6ff0Q=s64","userId":"00962902516379623090"}},"colab":{"base_uri":"https://localhost:8080/","height":295}},"source":["name =\"RNN BiLSTM attn_model\"\n","# compute precesion,recall for various thresholds\n","precision_nn, recall_nn, thresholds_nn = precision_recall_curve(y_test, predictions_nn_test)\n","# compute the area under curve\n","area_nn = auc(recall_nn, precision_nn)\n","\n","\n","# plot the AUC curve for MLP\n","plt.plot(recall_nn, precision_nn, label='Precision-Recall curve')\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.ylim([0.0, 1.05])\n","plt.xlim([0.0, 1.0])\n","plt.title('Precision-Recall %s: AUC=%0.2f' %(name,area_nn))\n","plt.legend(loc=\"lower left\")\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6ea0cuH7CeSs","colab":{}},"source":["#  build mlp model to tune the hyperparameters\n","def create_model(optimizer=\"adam\", dropout=0.2, dense_nparams=256):\n","    inputs = Input((max_length,))\n","    embeddings = Embedding(vocab,embedding_dim, weights=[embedding_matrix], \n","                        input_length=max_length, mask_zero=True, trainable=False)(inputs)\n","    drop_emb = Dropout(dropout)(embeddings)\n","    bilstm = Bidirectional(LSTM(units=LSTM_SIZE, return_sequences=True,recurrent_dropout = dropout))(drop_emb)\n","    bilstm = Bidirectional(LSTM(units=LSTM_SIZE, return_sequences=True,recurrent_dropout = dropout))(bilstm)\n","    #x, attn = LinearAttention(return_attention=True)(bilstm)\n","    x, attn = DeepAttention(return_attention=True)(bilstm)\n","    out = Dense(units=dense_nparams, activation=\"relu\")(x) \n","    out = Dense(units=N_CLASSES, activation=\"sigmoid\")(out)\n","    model2 = Model(inputs, out)\n","    model2.compile(loss='binary_crossentropy',\n","                  optimizer=optimizer,metrics=[precision, recall, f1, accuracy])\n","    return model2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rQFym1RfCkaU","colab":{}},"source":["from keras.wrappers.scikit_learn import KerasClassifier\n","from sklearn.pipeline import Pipeline\n","mymodel = KerasClassifier(build_fn=create_model, verbose=2)\n","# create a pipeline of the hyperparameter\n","lr_pipeline = Pipeline([\n","    ('kc', mymodel)])\n","grid_params = {\n","    'kc__epochs': [20],\n","    'kc__dense_nparams': [512,700],\n","    'kc__dropout': [0.3,0.5,],\n","    'kc__batch_size':[128,64],\n","    }"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3gD6SzKHCcf6","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import RandomizedSearchCV\n","# random grid search \n","clf2 = RandomizedSearchCV(lr_pipeline, grid_params,verbose=2,cv=3)\n","clf2.fit(x_train,y_train)\n","print(\"Best Score: \", clf2.best_score_)\n","print(\"Best Params: \", clf2.best_params_)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z98XnwWNCtFl","colab_type":"code","outputId":"e20703a4-2999-457d-ce70-5f02fa7cb723","executionInfo":{"status":"ok","timestamp":1583883182912,"user_tz":-120,"elapsed":112083,"user":{"displayName":"Panagiotis Kolozis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjr5mKsFQESGYRkXpGpagCBYUv0mGlapc3Ok6ff0Q=s64","userId":"00962902516379623090"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from keras.layers import GlobalAveragePooling1D\n","\n","model_mlp = Sequential()\n","model_mlp.add(Embedding(vocab,embedding_dim, weights=[embedding_matrix], \n","                    input_length=max_length, mask_zero=True, trainable=False))\n","model_mlp.add(GlobalAveragePooling1D())\n","model_mlp.add(Dropout(0.2))\n","model_mlp.add(Dense(300, activation='tanh'))\n","model_mlp.add(Dropout(0.2))\n","model_mlp.add(Dense(200,  activation='tanh'))\n","model_mlp.add(Dropout(0.5))\n","model_mlp.add(Dense(1,  activation='sigmoid'))\n","\n","print(model_mlp.summary())\n","model_mlp.compile(loss='binary_crossentropy',optimizer=Adam(lr=0.0001), metrics=[precision, recall, f1, accuracy])\n","# monitor loss in validation set and save the minimum values\n","checkpoint = ModelCheckpoint('kerasfastex', monitor='val_loss', verbose=2, save_best_only=True, mode='min')\n","# monitor loss in validatin set and stop when starting to grow to avoid overfitting\n","early_stop = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=4, restore_best_weights=True)\n","history_mlp = model_mlp.fit(x_train,y_train,\n","              batch_size=200,\n","              epochs=100,\n","              verbose = 2,\n","              callbacks=[early_stop, checkpoint],\n","              validation_data=(x_dev,y_dev),\n","              shuffle=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential_22\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_14 (Embedding)     (None, 1410, 300)         12980100  \n","_________________________________________________________________\n","global_average_pooling1d_1 ( (None, 300)               0         \n","_________________________________________________________________\n","dropout_29 (Dropout)         (None, 300)               0         \n","_________________________________________________________________\n","dense_33 (Dense)             (None, 300)               90300     \n","_________________________________________________________________\n","dropout_30 (Dropout)         (None, 300)               0         \n","_________________________________________________________________\n","dense_34 (Dense)             (None, 200)               60200     \n","_________________________________________________________________\n","dropout_31 (Dropout)         (None, 200)               0         \n","_________________________________________________________________\n","dense_35 (Dense)             (None, 1)                 201       \n","=================================================================\n","Total params: 13,130,801\n","Trainable params: 150,701\n","Non-trainable params: 12,980,100\n","_________________________________________________________________\n","None\n","Train on 1620 samples, validate on 180 samples\n","Epoch 1/100\n"," - 2s - loss: 0.6942 - precision: 0.4667 - recall: 0.2000 - f1: 0.2780 - accuracy: 0.4864 - val_loss: 0.6919 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan - val_accuracy: 0.5167\n","\n","Epoch 00001: val_loss improved from inf to 0.69187, saving model to kerasfastex\n","Epoch 2/100\n"," - 0s - loss: 0.6923 - precision: 0.5481 - recall: 0.2623 - f1: 0.3529 - accuracy: 0.5222 - val_loss: 0.6908 - val_precision: 0.6667 - val_recall: 0.0230 - val_f1: 0.0444 - val_accuracy: 0.5222\n","\n","Epoch 00002: val_loss improved from 0.69187 to 0.69084, saving model to kerasfastex\n","Epoch 3/100\n"," - 0s - loss: 0.6916 - precision: 0.5249 - recall: 0.3052 - f1: 0.3828 - accuracy: 0.5148 - val_loss: 0.6899 - val_precision: 0.9231 - val_recall: 0.1379 - val_f1: 0.2400 - val_accuracy: 0.5778\n","\n","Epoch 00003: val_loss improved from 0.69084 to 0.68993, saving model to kerasfastex\n","Epoch 4/100\n"," - 0s - loss: 0.6898 - precision: 0.5712 - recall: 0.3784 - f1: 0.4532 - accuracy: 0.5463 - val_loss: 0.6889 - val_precision: 0.8462 - val_recall: 0.2529 - val_f1: 0.3894 - val_accuracy: 0.6167\n","\n","Epoch 00004: val_loss improved from 0.68993 to 0.68890, saving model to kerasfastex\n","Epoch 5/100\n"," - 0s - loss: 0.6890 - precision: 0.5860 - recall: 0.4855 - f1: 0.5281 - accuracy: 0.5710 - val_loss: 0.6882 - val_precision: 0.7143 - val_recall: 0.5747 - val_f1: 0.6369 - val_accuracy: 0.6833\n","\n","Epoch 00005: val_loss improved from 0.68890 to 0.68821, saving model to kerasfastex\n","Epoch 6/100\n"," - 0s - loss: 0.6877 - precision: 0.5748 - recall: 0.6122 - f1: 0.5902 - accuracy: 0.5778 - val_loss: 0.6875 - val_precision: 0.6239 - val_recall: 0.8391 - val_f1: 0.7157 - val_accuracy: 0.6778\n","\n","Epoch 00006: val_loss improved from 0.68821 to 0.68749, saving model to kerasfastex\n","Epoch 7/100\n"," - 0s - loss: 0.6860 - precision: 0.6030 - recall: 0.6750 - f1: 0.6360 - accuracy: 0.6148 - val_loss: 0.6860 - val_precision: 0.6591 - val_recall: 0.6667 - val_f1: 0.6629 - val_accuracy: 0.6722\n","\n","Epoch 00007: val_loss improved from 0.68749 to 0.68604, saving model to kerasfastex\n","Epoch 8/100\n"," - 0s - loss: 0.6851 - precision: 0.6251 - recall: 0.5950 - f1: 0.6089 - accuracy: 0.6191 - val_loss: 0.6845 - val_precision: 0.7358 - val_recall: 0.4483 - val_f1: 0.5571 - val_accuracy: 0.6556\n","\n","Epoch 00008: val_loss improved from 0.68604 to 0.68445, saving model to kerasfastex\n","Epoch 9/100\n"," - 0s - loss: 0.6834 - precision: 0.7217 - recall: 0.4243 - f1: 0.5272 - accuracy: 0.6253 - val_loss: 0.6827 - val_precision: 0.8462 - val_recall: 0.2529 - val_f1: 0.3894 - val_accuracy: 0.6167\n","\n","Epoch 00009: val_loss improved from 0.68445 to 0.68273, saving model to kerasfastex\n","Epoch 10/100\n"," - 0s - loss: 0.6829 - precision: 0.7102 - recall: 0.3529 - f1: 0.4688 - accuracy: 0.6056 - val_loss: 0.6816 - val_precision: 0.7561 - val_recall: 0.3563 - val_f1: 0.4844 - val_accuracy: 0.6333\n","\n","Epoch 00010: val_loss improved from 0.68273 to 0.68158, saving model to kerasfastex\n","Epoch 11/100\n"," - 0s - loss: 0.6810 - precision: 0.6894 - recall: 0.4588 - f1: 0.5480 - accuracy: 0.6265 - val_loss: 0.6803 - val_precision: 0.7500 - val_recall: 0.4828 - val_f1: 0.5874 - val_accuracy: 0.6722\n","\n","Epoch 00011: val_loss improved from 0.68158 to 0.68032, saving model to kerasfastex\n","Epoch 12/100\n"," - 0s - loss: 0.6800 - precision: 0.6676 - recall: 0.5577 - f1: 0.6066 - accuracy: 0.6407 - val_loss: 0.6790 - val_precision: 0.7051 - val_recall: 0.6322 - val_f1: 0.6667 - val_accuracy: 0.6944\n","\n","Epoch 00012: val_loss improved from 0.68032 to 0.67902, saving model to kerasfastex\n","Epoch 13/100\n"," - 0s - loss: 0.6790 - precision: 0.6489 - recall: 0.6364 - f1: 0.6408 - accuracy: 0.6457 - val_loss: 0.6778 - val_precision: 0.6421 - val_recall: 0.7011 - val_f1: 0.6703 - val_accuracy: 0.6667\n","\n","Epoch 00013: val_loss improved from 0.67902 to 0.67776, saving model to kerasfastex\n","Epoch 14/100\n"," - 0s - loss: 0.6770 - precision: 0.6219 - recall: 0.7740 - f1: 0.6878 - accuracy: 0.6488 - val_loss: 0.6768 - val_precision: 0.6637 - val_recall: 0.8621 - val_f1: 0.7500 - val_accuracy: 0.7222\n","\n","Epoch 00014: val_loss improved from 0.67776 to 0.67675, saving model to kerasfastex\n","Epoch 15/100\n"," - 0s - loss: 0.6741 - precision: 0.6460 - recall: 0.7553 - f1: 0.6951 - accuracy: 0.6679 - val_loss: 0.6743 - val_precision: 0.6458 - val_recall: 0.7126 - val_f1: 0.6776 - val_accuracy: 0.6722\n","\n","Epoch 00015: val_loss improved from 0.67675 to 0.67434, saving model to kerasfastex\n","Epoch 16/100\n"," - 0s - loss: 0.6708 - precision: 0.6763 - recall: 0.7012 - f1: 0.6850 - accuracy: 0.6796 - val_loss: 0.6719 - val_precision: 0.6867 - val_recall: 0.6552 - val_f1: 0.6706 - val_accuracy: 0.6889\n","\n","Epoch 00016: val_loss improved from 0.67434 to 0.67192, saving model to kerasfastex\n","Epoch 17/100\n"," - 0s - loss: 0.6715 - precision: 0.6685 - recall: 0.6509 - f1: 0.6585 - accuracy: 0.6623 - val_loss: 0.6694 - val_precision: 0.7000 - val_recall: 0.6437 - val_f1: 0.6707 - val_accuracy: 0.6944\n","\n","Epoch 00017: val_loss improved from 0.67192 to 0.66940, saving model to kerasfastex\n","Epoch 18/100\n"," - 0s - loss: 0.6688 - precision: 0.6860 - recall: 0.6613 - f1: 0.6713 - accuracy: 0.6765 - val_loss: 0.6672 - val_precision: 0.6829 - val_recall: 0.6437 - val_f1: 0.6627 - val_accuracy: 0.6833\n","\n","Epoch 00018: val_loss improved from 0.66940 to 0.66716, saving model to kerasfastex\n","Epoch 19/100\n"," - 0s - loss: 0.6654 - precision: 0.6874 - recall: 0.6560 - f1: 0.6698 - accuracy: 0.6790 - val_loss: 0.6643 - val_precision: 0.7013 - val_recall: 0.6207 - val_f1: 0.6585 - val_accuracy: 0.6889\n","\n","Epoch 00019: val_loss improved from 0.66716 to 0.66431, saving model to kerasfastex\n","Epoch 20/100\n"," - 0s - loss: 0.6610 - precision: 0.7160 - recall: 0.6603 - f1: 0.6865 - accuracy: 0.6988 - val_loss: 0.6615 - val_precision: 0.7051 - val_recall: 0.6322 - val_f1: 0.6667 - val_accuracy: 0.6944\n","\n","Epoch 00020: val_loss improved from 0.66431 to 0.66148, saving model to kerasfastex\n","Epoch 21/100\n"," - 0s - loss: 0.6594 - precision: 0.7309 - recall: 0.6194 - f1: 0.6693 - accuracy: 0.6957 - val_loss: 0.6581 - val_precision: 0.7761 - val_recall: 0.5977 - val_f1: 0.6753 - val_accuracy: 0.7222\n","\n","Epoch 00021: val_loss improved from 0.66148 to 0.65814, saving model to kerasfastex\n","Epoch 22/100\n"," - 0s - loss: 0.6564 - precision: 0.7461 - recall: 0.5896 - f1: 0.6576 - accuracy: 0.6938 - val_loss: 0.6549 - val_precision: 0.7761 - val_recall: 0.5977 - val_f1: 0.6753 - val_accuracy: 0.7222\n","\n","Epoch 00022: val_loss improved from 0.65814 to 0.65494, saving model to kerasfastex\n","Epoch 23/100\n"," - 0s - loss: 0.6526 - precision: 0.7555 - recall: 0.6068 - f1: 0.6704 - accuracy: 0.7037 - val_loss: 0.6517 - val_precision: 0.7937 - val_recall: 0.5747 - val_f1: 0.6667 - val_accuracy: 0.7222\n","\n","Epoch 00023: val_loss improved from 0.65494 to 0.65167, saving model to kerasfastex\n","Epoch 24/100\n"," - 0s - loss: 0.6506 - precision: 0.7711 - recall: 0.5801 - f1: 0.6609 - accuracy: 0.7037 - val_loss: 0.6483 - val_precision: 0.7761 - val_recall: 0.5977 - val_f1: 0.6753 - val_accuracy: 0.7222\n","\n","Epoch 00024: val_loss improved from 0.65167 to 0.64827, saving model to kerasfastex\n","Epoch 25/100\n"," - 0s - loss: 0.6470 - precision: 0.7097 - recall: 0.6224 - f1: 0.6617 - accuracy: 0.6827 - val_loss: 0.6455 - val_precision: 0.6860 - val_recall: 0.6782 - val_f1: 0.6821 - val_accuracy: 0.6944\n","\n","Epoch 00025: val_loss improved from 0.64827 to 0.64548, saving model to kerasfastex\n","Epoch 26/100\n"," - 0s - loss: 0.6437 - precision: 0.7031 - recall: 0.7182 - f1: 0.7094 - accuracy: 0.7093 - val_loss: 0.6418 - val_precision: 0.6742 - val_recall: 0.6897 - val_f1: 0.6818 - val_accuracy: 0.6889\n","\n","Epoch 00026: val_loss improved from 0.64548 to 0.64180, saving model to kerasfastex\n","Epoch 27/100\n"," - 0s - loss: 0.6392 - precision: 0.7147 - recall: 0.6909 - f1: 0.7018 - accuracy: 0.7074 - val_loss: 0.6376 - val_precision: 0.7215 - val_recall: 0.6552 - val_f1: 0.6867 - val_accuracy: 0.7111\n","\n","Epoch 00027: val_loss improved from 0.64180 to 0.63755, saving model to kerasfastex\n","Epoch 28/100\n"," - 0s - loss: 0.6346 - precision: 0.7322 - recall: 0.6621 - f1: 0.6947 - accuracy: 0.7105 - val_loss: 0.6332 - val_precision: 0.7465 - val_recall: 0.6092 - val_f1: 0.6709 - val_accuracy: 0.7111\n","\n","Epoch 00028: val_loss improved from 0.63755 to 0.63323, saving model to kerasfastex\n","Epoch 29/100\n"," - 0s - loss: 0.6314 - precision: 0.7300 - recall: 0.6242 - f1: 0.6719 - accuracy: 0.6963 - val_loss: 0.6293 - val_precision: 0.7143 - val_recall: 0.6322 - val_f1: 0.6707 - val_accuracy: 0.7000\n","\n","Epoch 00029: val_loss improved from 0.63323 to 0.62935, saving model to kerasfastex\n","Epoch 30/100\n"," - 0s - loss: 0.6272 - precision: 0.7055 - recall: 0.7250 - f1: 0.7148 - accuracy: 0.7117 - val_loss: 0.6273 - val_precision: 0.6837 - val_recall: 0.7701 - val_f1: 0.7243 - val_accuracy: 0.7167\n","\n","Epoch 00030: val_loss improved from 0.62935 to 0.62735, saving model to kerasfastex\n","Epoch 31/100\n"," - 0s - loss: 0.6287 - precision: 0.6653 - recall: 0.7715 - f1: 0.7134 - accuracy: 0.6907 - val_loss: 0.6239 - val_precision: 0.6768 - val_recall: 0.7701 - val_f1: 0.7204 - val_accuracy: 0.7111\n","\n","Epoch 00031: val_loss improved from 0.62735 to 0.62387, saving model to kerasfastex\n","Epoch 32/100\n"," - 0s - loss: 0.6176 - precision: 0.6956 - recall: 0.7499 - f1: 0.7207 - accuracy: 0.7086 - val_loss: 0.6180 - val_precision: 0.7011 - val_recall: 0.7011 - val_f1: 0.7011 - val_accuracy: 0.7111\n","\n","Epoch 00032: val_loss improved from 0.62387 to 0.61797, saving model to kerasfastex\n","Epoch 33/100\n"," - 0s - loss: 0.6153 - precision: 0.7111 - recall: 0.6966 - f1: 0.7018 - accuracy: 0.7068 - val_loss: 0.6136 - val_precision: 0.7059 - val_recall: 0.6897 - val_f1: 0.6977 - val_accuracy: 0.7111\n","\n","Epoch 00033: val_loss improved from 0.61797 to 0.61359, saving model to kerasfastex\n","Epoch 34/100\n"," - 0s - loss: 0.6101 - precision: 0.7197 - recall: 0.7011 - f1: 0.7100 - accuracy: 0.7142 - val_loss: 0.6092 - val_precision: 0.7059 - val_recall: 0.6897 - val_f1: 0.6977 - val_accuracy: 0.7111\n","\n","Epoch 00034: val_loss improved from 0.61359 to 0.60920, saving model to kerasfastex\n","Epoch 35/100\n"," - 0s - loss: 0.6054 - precision: 0.7118 - recall: 0.7190 - f1: 0.7145 - accuracy: 0.7142 - val_loss: 0.6052 - val_precision: 0.6854 - val_recall: 0.7011 - val_f1: 0.6932 - val_accuracy: 0.7000\n","\n","Epoch 00035: val_loss improved from 0.60920 to 0.60515, saving model to kerasfastex\n","Epoch 36/100\n"," - 0s - loss: 0.5997 - precision: 0.7224 - recall: 0.7456 - f1: 0.7332 - accuracy: 0.7278 - val_loss: 0.6005 - val_precision: 0.6932 - val_recall: 0.7011 - val_f1: 0.6971 - val_accuracy: 0.7056\n","\n","Epoch 00036: val_loss improved from 0.60515 to 0.60045, saving model to kerasfastex\n","Epoch 37/100\n"," - 0s - loss: 0.6005 - precision: 0.7259 - recall: 0.6999 - f1: 0.7120 - accuracy: 0.7179 - val_loss: 0.5954 - val_precision: 0.7250 - val_recall: 0.6667 - val_f1: 0.6946 - val_accuracy: 0.7167\n","\n","Epoch 00037: val_loss improved from 0.60045 to 0.59537, saving model to kerasfastex\n","Epoch 38/100\n"," - 0s - loss: 0.5936 - precision: 0.7208 - recall: 0.7223 - f1: 0.7212 - accuracy: 0.7210 - val_loss: 0.5922 - val_precision: 0.6848 - val_recall: 0.7241 - val_f1: 0.7039 - val_accuracy: 0.7056\n","\n","Epoch 00038: val_loss improved from 0.59537 to 0.59222, saving model to kerasfastex\n","Epoch 39/100\n"," - 0s - loss: 0.5894 - precision: 0.7158 - recall: 0.7214 - f1: 0.7177 - accuracy: 0.7179 - val_loss: 0.5876 - val_precision: 0.6966 - val_recall: 0.7126 - val_f1: 0.7045 - val_accuracy: 0.7111\n","\n","Epoch 00039: val_loss improved from 0.59222 to 0.58762, saving model to kerasfastex\n","Epoch 40/100\n"," - 0s - loss: 0.5829 - precision: 0.7092 - recall: 0.7752 - f1: 0.7396 - accuracy: 0.7272 - val_loss: 0.5865 - val_precision: 0.6800 - val_recall: 0.7816 - val_f1: 0.7273 - val_accuracy: 0.7167\n","\n","Epoch 00040: val_loss improved from 0.58762 to 0.58648, saving model to kerasfastex\n","Epoch 41/100\n"," - 0s - loss: 0.5809 - precision: 0.7027 - recall: 0.7691 - f1: 0.7323 - accuracy: 0.7198 - val_loss: 0.5801 - val_precision: 0.6947 - val_recall: 0.7586 - val_f1: 0.7253 - val_accuracy: 0.7222\n","\n","Epoch 00041: val_loss improved from 0.58648 to 0.58012, saving model to kerasfastex\n","Epoch 42/100\n"," - 0s - loss: 0.5804 - precision: 0.7157 - recall: 0.7326 - f1: 0.7233 - accuracy: 0.7216 - val_loss: 0.5758 - val_precision: 0.6915 - val_recall: 0.7471 - val_f1: 0.7182 - val_accuracy: 0.7167\n","\n","Epoch 00042: val_loss improved from 0.58012 to 0.57583, saving model to kerasfastex\n","Epoch 43/100\n"," - 0s - loss: 0.5738 - precision: 0.7149 - recall: 0.7555 - f1: 0.7313 - accuracy: 0.7235 - val_loss: 0.5726 - val_precision: 0.6979 - val_recall: 0.7701 - val_f1: 0.7322 - val_accuracy: 0.7278\n","\n","Epoch 00043: val_loss improved from 0.57583 to 0.57259, saving model to kerasfastex\n","Epoch 44/100\n"," - 0s - loss: 0.5678 - precision: 0.7188 - recall: 0.7366 - f1: 0.7264 - accuracy: 0.7228 - val_loss: 0.5682 - val_precision: 0.7241 - val_recall: 0.7241 - val_f1: 0.7241 - val_accuracy: 0.7333\n","\n","Epoch 00044: val_loss improved from 0.57259 to 0.56821, saving model to kerasfastex\n","Epoch 45/100\n"," - 0s - loss: 0.5672 - precision: 0.7243 - recall: 0.7525 - f1: 0.7374 - accuracy: 0.7315 - val_loss: 0.5655 - val_precision: 0.6979 - val_recall: 0.7701 - val_f1: 0.7322 - val_accuracy: 0.7278\n","\n","Epoch 00045: val_loss improved from 0.56821 to 0.56553, saving model to kerasfastex\n","Epoch 46/100\n"," - 0s - loss: 0.5600 - precision: 0.7396 - recall: 0.7435 - f1: 0.7408 - accuracy: 0.7407 - val_loss: 0.5608 - val_precision: 0.7273 - val_recall: 0.7356 - val_f1: 0.7314 - val_accuracy: 0.7389\n","\n","Epoch 00046: val_loss improved from 0.56553 to 0.56082, saving model to kerasfastex\n","Epoch 47/100\n"," - 0s - loss: 0.5609 - precision: 0.7170 - recall: 0.7630 - f1: 0.7383 - accuracy: 0.7296 - val_loss: 0.5589 - val_precision: 0.7010 - val_recall: 0.7816 - val_f1: 0.7391 - val_accuracy: 0.7333\n","\n","Epoch 00047: val_loss improved from 0.56082 to 0.55891, saving model to kerasfastex\n","Epoch 48/100\n"," - 0s - loss: 0.5586 - precision: 0.7294 - recall: 0.7563 - f1: 0.7422 - accuracy: 0.7395 - val_loss: 0.5531 - val_precision: 0.7356 - val_recall: 0.7356 - val_f1: 0.7356 - val_accuracy: 0.7444\n","\n","Epoch 00048: val_loss improved from 0.55891 to 0.55309, saving model to kerasfastex\n","Epoch 49/100\n"," - 0s - loss: 0.5519 - precision: 0.7597 - recall: 0.7123 - f1: 0.7347 - accuracy: 0.7426 - val_loss: 0.5492 - val_precision: 0.7356 - val_recall: 0.7356 - val_f1: 0.7356 - val_accuracy: 0.7444\n","\n","Epoch 00049: val_loss improved from 0.55309 to 0.54923, saving model to kerasfastex\n","Epoch 50/100\n"," - 0s - loss: 0.5508 - precision: 0.7340 - recall: 0.7471 - f1: 0.7402 - accuracy: 0.7377 - val_loss: 0.5499 - val_precision: 0.6970 - val_recall: 0.7931 - val_f1: 0.7419 - val_accuracy: 0.7333\n","\n","Epoch 00050: val_loss did not improve from 0.54923\n","Epoch 51/100\n"," - 0s - loss: 0.5434 - precision: 0.7217 - recall: 0.7886 - f1: 0.7532 - accuracy: 0.7426 - val_loss: 0.5443 - val_precision: 0.7053 - val_recall: 0.7701 - val_f1: 0.7363 - val_accuracy: 0.7333\n","\n","Epoch 00051: val_loss improved from 0.54923 to 0.54429, saving model to kerasfastex\n","Epoch 52/100\n"," - 0s - loss: 0.5420 - precision: 0.7356 - recall: 0.7388 - f1: 0.7360 - accuracy: 0.7358 - val_loss: 0.5402 - val_precision: 0.7204 - val_recall: 0.7701 - val_f1: 0.7444 - val_accuracy: 0.7444\n","\n","Epoch 00052: val_loss improved from 0.54429 to 0.54021, saving model to kerasfastex\n","Epoch 53/100\n"," - 0s - loss: 0.5367 - precision: 0.7406 - recall: 0.7775 - f1: 0.7577 - accuracy: 0.7525 - val_loss: 0.5376 - val_precision: 0.7158 - val_recall: 0.7816 - val_f1: 0.7473 - val_accuracy: 0.7444\n","\n","Epoch 00053: val_loss improved from 0.54021 to 0.53756, saving model to kerasfastex\n","Epoch 54/100\n"," - 0s - loss: 0.5354 - precision: 0.7302 - recall: 0.7728 - f1: 0.7497 - accuracy: 0.7444 - val_loss: 0.5338 - val_precision: 0.7174 - val_recall: 0.7586 - val_f1: 0.7374 - val_accuracy: 0.7389\n","\n","Epoch 00054: val_loss improved from 0.53756 to 0.53379, saving model to kerasfastex\n","Epoch 55/100\n"," - 0s - loss: 0.5319 - precision: 0.7615 - recall: 0.7343 - f1: 0.7453 - accuracy: 0.7500 - val_loss: 0.5304 - val_precision: 0.7471 - val_recall: 0.7471 - val_f1: 0.7471 - val_accuracy: 0.7556\n","\n","Epoch 00055: val_loss improved from 0.53379 to 0.53039, saving model to kerasfastex\n","Epoch 56/100\n"," - 0s - loss: 0.5298 - precision: 0.7334 - recall: 0.7659 - f1: 0.7478 - accuracy: 0.7438 - val_loss: 0.5320 - val_precision: 0.7000 - val_recall: 0.8046 - val_f1: 0.7487 - val_accuracy: 0.7389\n","\n","Epoch 00056: val_loss did not improve from 0.53039\n","Epoch 57/100\n"," - 0s - loss: 0.5310 - precision: 0.7320 - recall: 0.7801 - f1: 0.7544 - accuracy: 0.7475 - val_loss: 0.5250 - val_precision: 0.7363 - val_recall: 0.7701 - val_f1: 0.7528 - val_accuracy: 0.7556\n","\n","Epoch 00057: val_loss improved from 0.53039 to 0.52495, saving model to kerasfastex\n","Epoch 58/100\n"," - 0s - loss: 0.5204 - precision: 0.7674 - recall: 0.7541 - f1: 0.7601 - accuracy: 0.7611 - val_loss: 0.5217 - val_precision: 0.7470 - val_recall: 0.7126 - val_f1: 0.7294 - val_accuracy: 0.7444\n","\n","Epoch 00058: val_loss improved from 0.52495 to 0.52170, saving model to kerasfastex\n","Epoch 59/100\n"," - 0s - loss: 0.5208 - precision: 0.7684 - recall: 0.7328 - f1: 0.7484 - accuracy: 0.7549 - val_loss: 0.5221 - val_precision: 0.7216 - val_recall: 0.8046 - val_f1: 0.7609 - val_accuracy: 0.7556\n","\n","Epoch 00059: val_loss did not improve from 0.52170\n","Epoch 60/100\n"," - 0s - loss: 0.5303 - precision: 0.7146 - recall: 0.8191 - f1: 0.7616 - accuracy: 0.7438 - val_loss: 0.5270 - val_precision: 0.6990 - val_recall: 0.8276 - val_f1: 0.7579 - val_accuracy: 0.7444\n","\n","Epoch 00060: val_loss did not improve from 0.52170\n","Epoch 61/100\n"," - 0s - loss: 0.5220 - precision: 0.7406 - recall: 0.7772 - f1: 0.7572 - accuracy: 0.7519 - val_loss: 0.5140 - val_precision: 0.7711 - val_recall: 0.7356 - val_f1: 0.7529 - val_accuracy: 0.7667\n","\n","Epoch 00061: val_loss improved from 0.52170 to 0.51400, saving model to kerasfastex\n","Epoch 62/100\n"," - 0s - loss: 0.5174 - precision: 0.7628 - recall: 0.7462 - f1: 0.7522 - accuracy: 0.7562 - val_loss: 0.5137 - val_precision: 0.7340 - val_recall: 0.7931 - val_f1: 0.7624 - val_accuracy: 0.7611\n","\n","Epoch 00062: val_loss improved from 0.51400 to 0.51366, saving model to kerasfastex\n","Epoch 63/100\n"," - 0s - loss: 0.5122 - precision: 0.7761 - recall: 0.7524 - f1: 0.7626 - accuracy: 0.7667 - val_loss: 0.5107 - val_precision: 0.7416 - val_recall: 0.7586 - val_f1: 0.7500 - val_accuracy: 0.7556\n","\n","Epoch 00063: val_loss improved from 0.51366 to 0.51066, saving model to kerasfastex\n","Epoch 64/100\n"," - 0s - loss: 0.5170 - precision: 0.7554 - recall: 0.7606 - f1: 0.7562 - accuracy: 0.7568 - val_loss: 0.5107 - val_precision: 0.7143 - val_recall: 0.8046 - val_f1: 0.7568 - val_accuracy: 0.7500\n","\n","Epoch 00064: val_loss improved from 0.51066 to 0.51066, saving model to kerasfastex\n","Epoch 65/100\n"," - 0s - loss: 0.5027 - precision: 0.7701 - recall: 0.7749 - f1: 0.7697 - accuracy: 0.7691 - val_loss: 0.5057 - val_precision: 0.7586 - val_recall: 0.7586 - val_f1: 0.7586 - val_accuracy: 0.7667\n","\n","Epoch 00065: val_loss improved from 0.51066 to 0.50570, saving model to kerasfastex\n","Epoch 66/100\n"," - 0s - loss: 0.5031 - precision: 0.7820 - recall: 0.7534 - f1: 0.7663 - accuracy: 0.7704 - val_loss: 0.5028 - val_precision: 0.7529 - val_recall: 0.7356 - val_f1: 0.7442 - val_accuracy: 0.7556\n","\n","Epoch 00066: val_loss improved from 0.50570 to 0.50279, saving model to kerasfastex\n","Epoch 67/100\n"," - 0s - loss: 0.4939 - precision: 0.7965 - recall: 0.7694 - f1: 0.7821 - accuracy: 0.7858 - val_loss: 0.5019 - val_precision: 0.7340 - val_recall: 0.7931 - val_f1: 0.7624 - val_accuracy: 0.7611\n","\n","Epoch 00067: val_loss improved from 0.50279 to 0.50188, saving model to kerasfastex\n","Epoch 68/100\n"," - 0s - loss: 0.4996 - precision: 0.7612 - recall: 0.7929 - f1: 0.7760 - accuracy: 0.7716 - val_loss: 0.5016 - val_precision: 0.7245 - val_recall: 0.8161 - val_f1: 0.7676 - val_accuracy: 0.7611\n","\n","Epoch 00068: val_loss improved from 0.50188 to 0.50164, saving model to kerasfastex\n","Epoch 69/100\n"," - 0s - loss: 0.4970 - precision: 0.7685 - recall: 0.7808 - f1: 0.7734 - accuracy: 0.7728 - val_loss: 0.4965 - val_precision: 0.7471 - val_recall: 0.7471 - val_f1: 0.7471 - val_accuracy: 0.7556\n","\n","Epoch 00069: val_loss improved from 0.50164 to 0.49653, saving model to kerasfastex\n","Epoch 70/100\n"," - 0s - loss: 0.4940 - precision: 0.8029 - recall: 0.7410 - f1: 0.7696 - accuracy: 0.7790 - val_loss: 0.4942 - val_precision: 0.7778 - val_recall: 0.7241 - val_f1: 0.7500 - val_accuracy: 0.7667\n","\n","Epoch 00070: val_loss improved from 0.49653 to 0.49421, saving model to kerasfastex\n","Epoch 71/100\n"," - 0s - loss: 0.4888 - precision: 0.7774 - recall: 0.7673 - f1: 0.7719 - accuracy: 0.7747 - val_loss: 0.4972 - val_precision: 0.7200 - val_recall: 0.8276 - val_f1: 0.7701 - val_accuracy: 0.7611\n","\n","Epoch 00071: val_loss did not improve from 0.49421\n","Epoch 72/100\n"," - 0s - loss: 0.4982 - precision: 0.7586 - recall: 0.7995 - f1: 0.7782 - accuracy: 0.7722 - val_loss: 0.4945 - val_precision: 0.7273 - val_recall: 0.8276 - val_f1: 0.7742 - val_accuracy: 0.7667\n","\n","Epoch 00072: val_loss did not improve from 0.49421\n","Epoch 73/100\n"," - 0s - loss: 0.4817 - precision: 0.7757 - recall: 0.7954 - f1: 0.7849 - accuracy: 0.7827 - val_loss: 0.4900 - val_precision: 0.7500 - val_recall: 0.7931 - val_f1: 0.7709 - val_accuracy: 0.7722\n","\n","Epoch 00073: val_loss improved from 0.49421 to 0.48998, saving model to kerasfastex\n","Epoch 74/100\n"," - 0s - loss: 0.4908 - precision: 0.7801 - recall: 0.7793 - f1: 0.7795 - accuracy: 0.7796 - val_loss: 0.4873 - val_precision: 0.7444 - val_recall: 0.7701 - val_f1: 0.7571 - val_accuracy: 0.7611\n","\n","Epoch 00074: val_loss improved from 0.48998 to 0.48733, saving model to kerasfastex\n","Epoch 75/100\n"," - 0s - loss: 0.4932 - precision: 0.7850 - recall: 0.7432 - f1: 0.7623 - accuracy: 0.7685 - val_loss: 0.4850 - val_precision: 0.7586 - val_recall: 0.7586 - val_f1: 0.7586 - val_accuracy: 0.7667\n","\n","Epoch 00075: val_loss improved from 0.48733 to 0.48498, saving model to kerasfastex\n","Epoch 76/100\n"," - 0s - loss: 0.4886 - precision: 0.7882 - recall: 0.7667 - f1: 0.7765 - accuracy: 0.7796 - val_loss: 0.4847 - val_precision: 0.7527 - val_recall: 0.8046 - val_f1: 0.7778 - val_accuracy: 0.7778\n","\n","Epoch 00076: val_loss improved from 0.48498 to 0.48469, saving model to kerasfastex\n","Epoch 77/100\n"," - 0s - loss: 0.4792 - precision: 0.7767 - recall: 0.7985 - f1: 0.7867 - accuracy: 0.7858 - val_loss: 0.4843 - val_precision: 0.7527 - val_recall: 0.8046 - val_f1: 0.7778 - val_accuracy: 0.7778\n","\n","Epoch 00077: val_loss improved from 0.48469 to 0.48431, saving model to kerasfastex\n","Epoch 78/100\n"," - 0s - loss: 0.4805 - precision: 0.7962 - recall: 0.7573 - f1: 0.7751 - accuracy: 0.7815 - val_loss: 0.4808 - val_precision: 0.7614 - val_recall: 0.7701 - val_f1: 0.7657 - val_accuracy: 0.7722\n","\n","Epoch 00078: val_loss improved from 0.48431 to 0.48079, saving model to kerasfastex\n","Epoch 79/100\n"," - 0s - loss: 0.4871 - precision: 0.7780 - recall: 0.7846 - f1: 0.7807 - accuracy: 0.7809 - val_loss: 0.4821 - val_precision: 0.7447 - val_recall: 0.8046 - val_f1: 0.7735 - val_accuracy: 0.7722\n","\n","Epoch 00079: val_loss did not improve from 0.48079\n","Epoch 80/100\n"," - 0s - loss: 0.4840 - precision: 0.7626 - recall: 0.7880 - f1: 0.7728 - accuracy: 0.7698 - val_loss: 0.4804 - val_precision: 0.7447 - val_recall: 0.8046 - val_f1: 0.7735 - val_accuracy: 0.7722\n","\n","Epoch 00080: val_loss improved from 0.48079 to 0.48043, saving model to kerasfastex\n","Epoch 81/100\n"," - 0s - loss: 0.4726 - precision: 0.7958 - recall: 0.7924 - f1: 0.7930 - accuracy: 0.7938 - val_loss: 0.4772 - val_precision: 0.7692 - val_recall: 0.8046 - val_f1: 0.7865 - val_accuracy: 0.7889\n","\n","Epoch 00081: val_loss improved from 0.48043 to 0.47717, saving model to kerasfastex\n","Epoch 82/100\n"," - 0s - loss: 0.4670 - precision: 0.7899 - recall: 0.7828 - f1: 0.7855 - accuracy: 0.7870 - val_loss: 0.4742 - val_precision: 0.7727 - val_recall: 0.7816 - val_f1: 0.7771 - val_accuracy: 0.7833\n","\n","Epoch 00082: val_loss improved from 0.47717 to 0.47417, saving model to kerasfastex\n","Epoch 83/100\n"," - 0s - loss: 0.4829 - precision: 0.7861 - recall: 0.7594 - f1: 0.7707 - accuracy: 0.7741 - val_loss: 0.4744 - val_precision: 0.7634 - val_recall: 0.8161 - val_f1: 0.7889 - val_accuracy: 0.7889\n","\n","Epoch 00083: val_loss did not improve from 0.47417\n","Epoch 84/100\n"," - 0s - loss: 0.4671 - precision: 0.7763 - recall: 0.8076 - f1: 0.7910 - accuracy: 0.7895 - val_loss: 0.4723 - val_precision: 0.7634 - val_recall: 0.8161 - val_f1: 0.7889 - val_accuracy: 0.7889\n","\n","Epoch 00084: val_loss improved from 0.47417 to 0.47230, saving model to kerasfastex\n","Epoch 85/100\n"," - 0s - loss: 0.4715 - precision: 0.7834 - recall: 0.7888 - f1: 0.7853 - accuracy: 0.7858 - val_loss: 0.4708 - val_precision: 0.7634 - val_recall: 0.8161 - val_f1: 0.7889 - val_accuracy: 0.7889\n","\n","Epoch 00085: val_loss improved from 0.47230 to 0.47083, saving model to kerasfastex\n","Epoch 86/100\n"," - 0s - loss: 0.4710 - precision: 0.7953 - recall: 0.7710 - f1: 0.7820 - accuracy: 0.7852 - val_loss: 0.4675 - val_precision: 0.7816 - val_recall: 0.7816 - val_f1: 0.7816 - val_accuracy: 0.7889\n","\n","Epoch 00086: val_loss improved from 0.47083 to 0.46754, saving model to kerasfastex\n","Epoch 87/100\n"," - 0s - loss: 0.4657 - precision: 0.7873 - recall: 0.7903 - f1: 0.7877 - accuracy: 0.7877 - val_loss: 0.4707 - val_precision: 0.7553 - val_recall: 0.8161 - val_f1: 0.7845 - val_accuracy: 0.7833\n","\n","Epoch 00087: val_loss did not improve from 0.46754\n","Epoch 88/100\n"," - 0s - loss: 0.4704 - precision: 0.7681 - recall: 0.8206 - f1: 0.7930 - accuracy: 0.7870 - val_loss: 0.4663 - val_precision: 0.7609 - val_recall: 0.8046 - val_f1: 0.7821 - val_accuracy: 0.7833\n","\n","Epoch 00088: val_loss improved from 0.46754 to 0.46634, saving model to kerasfastex\n","Epoch 89/100\n"," - 0s - loss: 0.4589 - precision: 0.7956 - recall: 0.7793 - f1: 0.7864 - accuracy: 0.7889 - val_loss: 0.4640 - val_precision: 0.7778 - val_recall: 0.8046 - val_f1: 0.7910 - val_accuracy: 0.7944\n","\n","Epoch 00089: val_loss improved from 0.46634 to 0.46405, saving model to kerasfastex\n","Epoch 90/100\n"," - 0s - loss: 0.4688 - precision: 0.7678 - recall: 0.8208 - f1: 0.7919 - accuracy: 0.7846 - val_loss: 0.4716 - val_precision: 0.7200 - val_recall: 0.8276 - val_f1: 0.7701 - val_accuracy: 0.7611\n","\n","Epoch 00090: val_loss did not improve from 0.46405\n","Epoch 91/100\n"," - 0s - loss: 0.4648 - precision: 0.7636 - recall: 0.8378 - f1: 0.7976 - accuracy: 0.7883 - val_loss: 0.4612 - val_precision: 0.7753 - val_recall: 0.7931 - val_f1: 0.7841 - val_accuracy: 0.7889\n","\n","Epoch 00091: val_loss improved from 0.46405 to 0.46120, saving model to kerasfastex\n","Epoch 92/100\n"," - 0s - loss: 0.4630 - precision: 0.8262 - recall: 0.7384 - f1: 0.7792 - accuracy: 0.7914 - val_loss: 0.4613 - val_precision: 0.8333 - val_recall: 0.7471 - val_f1: 0.7879 - val_accuracy: 0.8056\n","\n","Epoch 00092: val_loss did not improve from 0.46120\n","Epoch 93/100\n"," - 0s - loss: 0.4572 - precision: 0.8180 - recall: 0.7756 - f1: 0.7931 - accuracy: 0.7988 - val_loss: 0.4630 - val_precision: 0.7553 - val_recall: 0.8161 - val_f1: 0.7845 - val_accuracy: 0.7833\n","\n","Epoch 00093: val_loss did not improve from 0.46120\n","Epoch 94/100\n"," - 0s - loss: 0.4585 - precision: 0.7797 - recall: 0.8122 - f1: 0.7953 - accuracy: 0.7920 - val_loss: 0.4585 - val_precision: 0.7778 - val_recall: 0.8046 - val_f1: 0.7910 - val_accuracy: 0.7944\n","\n","Epoch 00094: val_loss improved from 0.46120 to 0.45845, saving model to kerasfastex\n","Epoch 95/100\n"," - 0s - loss: 0.4572 - precision: 0.8071 - recall: 0.7756 - f1: 0.7903 - accuracy: 0.7938 - val_loss: 0.4563 - val_precision: 0.7882 - val_recall: 0.7701 - val_f1: 0.7791 - val_accuracy: 0.7889\n","\n","Epoch 00095: val_loss improved from 0.45845 to 0.45628, saving model to kerasfastex\n","Epoch 96/100\n"," - 0s - loss: 0.4622 - precision: 0.7957 - recall: 0.7730 - f1: 0.7834 - accuracy: 0.7877 - val_loss: 0.4579 - val_precision: 0.7634 - val_recall: 0.8161 - val_f1: 0.7889 - val_accuracy: 0.7889\n","\n","Epoch 00096: val_loss did not improve from 0.45628\n","Epoch 97/100\n"," - 0s - loss: 0.4537 - precision: 0.8025 - recall: 0.7860 - f1: 0.7935 - accuracy: 0.7957 - val_loss: 0.4557 - val_precision: 0.7692 - val_recall: 0.8046 - val_f1: 0.7865 - val_accuracy: 0.7889\n","\n","Epoch 00097: val_loss improved from 0.45628 to 0.45574, saving model to kerasfastex\n","Epoch 98/100\n"," - 0s - loss: 0.4620 - precision: 0.7692 - recall: 0.8262 - f1: 0.7960 - accuracy: 0.7895 - val_loss: 0.4565 - val_precision: 0.7553 - val_recall: 0.8161 - val_f1: 0.7845 - val_accuracy: 0.7833\n","\n","Epoch 00098: val_loss did not improve from 0.45574\n","Epoch 99/100\n"," - 0s - loss: 0.4651 - precision: 0.7967 - recall: 0.7408 - f1: 0.7663 - accuracy: 0.7765 - val_loss: 0.4521 - val_precision: 0.7882 - val_recall: 0.7701 - val_f1: 0.7791 - val_accuracy: 0.7889\n","\n","Epoch 00099: val_loss improved from 0.45574 to 0.45211, saving model to kerasfastex\n","Epoch 100/100\n"," - 0s - loss: 0.4594 - precision: 0.7878 - recall: 0.7943 - f1: 0.7883 - accuracy: 0.7877 - val_loss: 0.4550 - val_precision: 0.7553 - val_recall: 0.8161 - val_f1: 0.7845 - val_accuracy: 0.7833\n","\n","Epoch 00100: val_loss did not improve from 0.45211\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ll511t6ZEoW6","colab_type":"code","outputId":"209cfff8-b2df-49bd-96e5-090b68ca515b","executionInfo":{"status":"ok","timestamp":1583883305761,"user_tz":-120,"elapsed":827,"user":{"displayName":"Panagiotis Kolozis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjr5mKsFQESGYRkXpGpagCBYUv0mGlapc3Ok6ff0Q=s64","userId":"00962902516379623090"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["predictions_mlp_train = model_mlp.predict(np.array(x_train))\n","print('F1 score with macro averaging in train set for mlp',f1_score(y_train,np.round(predictions_mlp_train),average='macro'))\n","predictions_mlp_dev = model_mlp.predict(np.array(x_dev))\n","print('F1 score with macro averaging in dev set for mlp',f1_score(y_dev,np.round(predictions_mlp_dev),average='macro'))\n","predictions_mlp_test = model_mlp.predict(np.array(x_test))\n","print('F1 score with macro averaging in test set for mlp',f1_score(y_test,np.round(predictions_mlp_test),average='macro'))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["F1 score with macro averaging in train set for mlp 0.8226902616933702\n","F1 score with macro averaging in dev set for mlp 0.7833266458841321\n","F1 score with macro averaging in test set for mlp 0.7938403519798869\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"caFlbKYrBl2R","colab_type":"code","colab":{}},"source":["# H0 RNN perfoms as good as MLP : F1_NN = F1_MLP\n","# H1 RNN performs better than MLP : F1_NN > F1_MLP\n","\n","# n: lenght of test set\n","n = np.array(x_test).shape[0]\n","# b: samples draws\n","b = 1000\n","# the difference between F1 score of RNN and MLP \n","delta = f1_score(y_test,np.round(predictions_nn_test),average=\"macro\") - f1_score(y_test,np.round(predictions_mlp_test),average=\"macro\")\n","count = 0\n","for i in range(b):\n","  # draw random samples with replacement from the test sets  \n","    x,y = resample(np.array(x_test),np.array(y_test), n_samples=n)\n","    # in the random test sets predict the models\n","    RNN = model.predict(x)\n","    MLP = model_mlp.predict(x)\n","    # compute the difference in f1 scores in the random test samples\n","    diff = f1_score(np.round(RNN),y,average=\"macro\") - f1_score(np.round(MLP),y,average=\"macro\")\n","    if diff > 2*delta:\n","            count += 1\n","p_value = count/b\n","if p_value < 0.01:\n","    print(\"RNN performs better than MLP\")\n","    print(\"p-value:\",p_value)\n","else:\n","    print(\"RNN performs as good as MLP\")\n","    print(\"p-value:\",p_value)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JOi1oXXuDwZa","colab_type":"code","outputId":"b65909de-386d-4306-bd3f-67770b4f117a","executionInfo":{"status":"error","timestamp":1585565482635,"user_tz":-180,"elapsed":679,"user":{"displayName":"Alexandros Chasapis","photoUrl":"","userId":"04334621904766079219"}},"colab":{"base_uri":"https://localhost:8080/","height":337}},"source":["import numpy as np\n","from scipy.stats import random_correlation\n","x = random_correlation.rvs((.5, .8, 1.2, 1.5,,5,6,7,8,9))"],"execution_count":0,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-94901ffebfed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom_correlation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_correlation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/stats/_multivariate.py\u001b[0m in \u001b[0;36mrvs\u001b[0;34m(self, eigs, random_state, tol, diag_tol)\u001b[0m\n\u001b[1;32m   3716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3717\u001b[0m         \"\"\"\n\u001b[0;32m-> 3718\u001b[0;31m         \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meigs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meigs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3720\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/stats/_multivariate.py\u001b[0m in \u001b[0;36m_process_parameters\u001b[0;34m(self, eigs, tol)\u001b[0m\n\u001b[1;32m   3607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3608\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meigs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3609\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sum of eigenvalues must equal dimensionality.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3611\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meigs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Sum of eigenvalues must equal dimensionality."]}]},{"cell_type":"code","metadata":{"id":"aEJ4Gu8LEl9H","colab_type":"code","outputId":"5059133f-c475-4b0b-abdf-e6eb7713a9c4","executionInfo":{"status":"ok","timestamp":1585565585210,"user_tz":-180,"elapsed":1227,"user":{"displayName":"Alexandros Chasapis","photoUrl":"","userId":"04334621904766079219"}},"colab":{"base_uri":"https://localhost:8080/","height":353}},"source":["from scipy import random, linalg\n","matrixSize = 10 \n","A = random.rand(matrixSize,matrixSize)\n","B = np.dot(A,A.transpose())\n","print('random positive semi-define matrix for today is', B)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["random positive semi-define matrix for today is [[1.97464736 1.84568814 1.6407832  1.47624155 1.86605723 2.22168599\n","  1.20813387 2.18976976 1.55746027 2.20006908]\n"," [1.84568814 3.70644647 2.45019561 2.98102946 3.43282729 3.22294636\n","  2.52276776 2.88857325 1.96066929 3.6257779 ]\n"," [1.6407832  2.45019561 3.46630281 2.57948692 2.57210382 2.69572042\n","  2.0859285  3.13560641 2.23849957 3.17553761]\n"," [1.47624155 2.98102946 2.57948692 3.7435883  2.9176656  2.72328391\n","  2.46045536 3.02560236 2.13233858 3.16546986]\n"," [1.86605723 3.43282729 2.57210382 2.9176656  3.56705008 3.12180785\n","  2.36937822 3.05630922 2.2097847  3.39589002]\n"," [2.22168599 3.22294636 2.69572042 2.72328391 3.12180785 5.0449386\n","  3.21487546 3.4200839  2.26804351 3.34312871]\n"," [1.20813387 2.52276776 2.0859285  2.46045536 2.36937822 3.21487546\n","  2.56813751 2.37138234 1.46157804 2.63264539]\n"," [2.18976976 2.88857325 3.13560641 3.02560236 3.05630922 3.4200839\n","  2.37138234 3.96792392 2.5387595  3.55570104]\n"," [1.55746027 1.96066929 2.23849957 2.13233858 2.2097847  2.26804351\n","  1.46157804 2.5387595  2.49489639 2.42821946]\n"," [2.20006908 3.6257779  3.17553761 3.16546986 3.39589002 3.34312871\n","  2.63264539 3.55570104 2.42821946 4.21777194]]\n"],"name":"stdout"}]}]}